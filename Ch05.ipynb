{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Anomaly Detection in Network Traffic with K-means Clustering\n",
    "http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Ch05\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A First Take on Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataWithoutHeader = spark.read.option('inferSchema', 'true') \\\n",
    "                            .option('header', 'false') \\\n",
    "                            .csv('kddcup.data_10_percent_corrected')\n",
    "# 10% sampling dataser --> 500k rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataWithoutHeader.toDF(\n",
    "\"duration\", \"protocol_type\", \"service\", \"flag\",\n",
    "\"src_bytes\", \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\",\n",
    "\"hot\", \"num_failed_logins\", \"logged_in\", \"num_compromised\",\n",
    "\"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n",
    "\"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n",
    "\"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\",\n",
    "\"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\",\n",
    "\"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\",\n",
    "\"dst_host_count\", \"dst_host_srv_count\",\n",
    "\"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\",\n",
    "\"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
    "\"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "\"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\",\n",
    "\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|           label| count|\n",
      "+----------------+------+\n",
      "|          smurf.|280790|\n",
      "|        neptune.|107201|\n",
      "|         normal.| 97278|\n",
      "|           back.|  2203|\n",
      "|          satan.|  1589|\n",
      "|        ipsweep.|  1247|\n",
      "|      portsweep.|  1040|\n",
      "|    warezclient.|  1020|\n",
      "|       teardrop.|   979|\n",
      "|            pod.|   264|\n",
      "|           nmap.|   231|\n",
      "|   guess_passwd.|    53|\n",
      "|buffer_overflow.|    30|\n",
      "|           land.|    21|\n",
      "|    warezmaster.|    20|\n",
      "|           imap.|    12|\n",
      "|        rootkit.|    10|\n",
      "|     loadmodule.|     9|\n",
      "|      ftp_write.|     8|\n",
      "|       multihop.|     7|\n",
      "|            phf.|     4|\n",
      "|           perl.|     3|\n",
      "|            spy.|     2|\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"label\").groupBy(\"label\").count().orderBy(\"count\", ascending=False).show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.clustering import KMeans, KMeansModel\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numericOnly = data.drop(\"protocol_type\", \"service\", \"flag\").dropna().cache()\n",
    "numericOnly = data.drop(\"protocol_type\", \"service\", \"flag\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputCols = numericOnly.columns\n",
    "inputCols.remove('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler() \\\n",
    "    .setInputCols(inputCols)\\\n",
    "    .setOutputCol(\"featureVector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans() \\\n",
    "    .setPredictionCol(\"cluster\") \\\n",
    "    .setFeaturesCol(\"featureVector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([4.79793956e+01, 1.62207883e+03, 8.68534183e+02, 4.45326100e-05,\n",
       "        6.43293794e-03, 1.41694668e-05, 3.45168212e-02, 1.51815716e-04,\n",
       "        1.48247035e-01, 1.02121372e-02, 1.11331525e-04, 3.64357718e-05,\n",
       "        1.13517671e-02, 1.08295211e-03, 1.09307315e-04, 1.00805635e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.38658354e-03, 3.32286248e+02,\n",
       "        2.92907143e+02, 1.76685418e-01, 1.76607809e-01, 5.74330999e-02,\n",
       "        5.77183920e-02, 7.91548844e-01, 2.09816404e-02, 2.89968625e-02,\n",
       "        2.32470732e+02, 1.88666046e+02, 7.53781203e-01, 3.09056111e-02,\n",
       "        6.01935529e-01, 6.68351484e-03, 1.76753957e-01, 1.76441622e-01,\n",
       "        5.81176268e-02, 5.74111170e-02]),\n",
       " array([2.0000000e+00, 6.9337564e+08, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 5.7000000e+01,\n",
       "        3.0000000e+00, 7.9000000e-01, 6.7000000e-01, 2.1000000e-01,\n",
       "        3.3000000e-01, 5.0000000e-02, 3.9000000e-01, 0.0000000e+00,\n",
       "        2.5500000e+02, 3.0000000e+00, 1.0000000e-02, 9.0000000e-02,\n",
       "        2.2000000e-01, 0.0000000e+00, 1.8000000e-01, 6.7000000e-01,\n",
       "        5.0000000e-02, 3.3000000e-01])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline().setStages([assembler, kmeans]) # stages -> transformer, estimator\n",
    "# pipeline = Pipeline(stages=[assembler, kmeans])\n",
    "pipelineModel = pipeline.fit(numericOnly)\n",
    "kmeansModel = pipelineModel.stages[-1]\n",
    "\n",
    "kmeansModel.clusterCenters() # k=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "withCluster = pipelineModel.transform(numericOnly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+------+\n",
      "|cluster|           label| count|\n",
      "+-------+----------------+------+\n",
      "|      0|          smurf.|280790|\n",
      "|      0|        neptune.|107201|\n",
      "|      0|         normal.| 97278|\n",
      "|      0|           back.|  2203|\n",
      "|      0|          satan.|  1589|\n",
      "|      0|        ipsweep.|  1247|\n",
      "|      0|      portsweep.|  1039|\n",
      "|      0|    warezclient.|  1020|\n",
      "|      0|       teardrop.|   979|\n",
      "|      0|            pod.|   264|\n",
      "|      0|           nmap.|   231|\n",
      "|      0|   guess_passwd.|    53|\n",
      "|      0|buffer_overflow.|    30|\n",
      "|      0|           land.|    21|\n",
      "|      0|    warezmaster.|    20|\n",
      "|      0|           imap.|    12|\n",
      "|      0|        rootkit.|    10|\n",
      "|      0|     loadmodule.|     9|\n",
      "|      0|      ftp_write.|     8|\n",
      "|      0|       multihop.|     7|\n",
      "|      0|            phf.|     4|\n",
      "|      0|           perl.|     3|\n",
      "|      0|            spy.|     2|\n",
      "|      1|      portsweep.|     1|\n",
      "+-------+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "withCluster.select(\"cluster\", \"label\") \\\n",
    "    .groupBy(\"cluster\", \"label\").count() \\\n",
    "    .orderBy([\"cluster\", \"count\"], ascending=[1, 0]) \\\n",
    "    .show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def clusteringScore0(data, k): # (data: DataFrame, k: Int): Double \n",
    "    inputCols = data.columns.copy()\n",
    "    inputCols.remove('label')\n",
    "\n",
    "    assembler = VectorAssembler() \\\n",
    "        .setInputCols(inputCols) \\\n",
    "        .setOutputCol(\"featureVector\")\n",
    "        \n",
    "    kmeans = KMeans() \\\n",
    "        .setSeed(42) \\\n",
    "        .setK(k) \\\n",
    "        .setPredictionCol(\"cluster\") \\\n",
    "        .setFeaturesCol(\"featureVector\")\n",
    "    \n",
    "    pipeline = Pipeline().setStages([assembler, kmeans])\n",
    "    kmeansModel = pipeline.fit(data).stages[-1]\n",
    "    return kmeansModel.computeCost(assembler.transform(data)) / data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20, 69904862.91838956),\n",
       " (40, 49086774.42579959),\n",
       " (60, 34134988.99795592),\n",
       " (80, 27900808.810133304),\n",
       " (100, 19701999.771263387)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores0 = map(lambda x: (x, clusteringScore0(numericOnly, x)) ,range(20, 101, 20))\n",
    "list(scores0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusteringScore1(data, k): # (data: DataFrame, k: Int): Double \n",
    "    inputCols = data.columns.copy()\n",
    "    inputCols.remove('label')\n",
    "\n",
    "    assembler = VectorAssembler() \\\n",
    "        .setInputCols(inputCols) \\\n",
    "        .setOutputCol(\"featureVector\")\n",
    "        \n",
    "    kmeans = KMeans() \\\n",
    "        .setSeed(random.randint(0,1000)) \\\n",
    "        .setK(k) \\\n",
    "        .setMaxIter(40) \\\n",
    "        .setTol(1.0e-5) \\\n",
    "        .setPredictionCol(\"cluster\") \\\n",
    "        .setFeaturesCol(\"featureVector\")\n",
    "    \n",
    "    pipeline = Pipeline().setStages([assembler, kmeans])\n",
    "    kmeansModel = pipeline.fit(data).stages[-1]\n",
    "    return kmeansModel.computeCost(assembler.transform(data)) / data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20, 54857135.05911902),\n",
       " (40, 69889095.30833218),\n",
       " (60, 27004024.474778596),\n",
       " (80, 14753113.896101408),\n",
       " (100, 6495327.519716123)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1 = map(lambda x: (x, clusteringScore1(numericOnly, x)) ,range(20, 101, 20))\n",
    "list(scores1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusteringScore2(data, k): #def clusteringScore2(data: DataFrame, k: Int): Double = {\n",
    "    inputCols = data.columns.copy()\n",
    "    inputCols.remove(\"label\")\n",
    "\n",
    "    assembler = VectorAssembler() \\\n",
    "        .setInputCols(inputCols) \\\n",
    "        .setOutputCol(\"featureVector\")\n",
    "    \n",
    "    scaler = StandardScaler() \\\n",
    "        .setInputCol(\"featureVector\") \\\n",
    "        .setOutputCol(\"scaledFeatureVector\") \\\n",
    "        .setWithStd(True) \\\n",
    "        .setWithMean(False)\n",
    "        \n",
    "    kmeans = KMeans() \\\n",
    "        .setSeed(42) \\\n",
    "        .setK(k) \\\n",
    "        .setMaxIter(40) \\\n",
    "        .setTol(1.0e-5) \\\n",
    "        .setPredictionCol(\"cluster\") \\\n",
    "        .setFeaturesCol(\"scaledFeatureVector\")\n",
    "    \n",
    "    pipeline = Pipeline().setStages([assembler, scaler, kmeans])\n",
    "    pipelineModel = pipeline.fit(data)\n",
    "    kmeansModel = pipelineModel.stages[-1]\n",
    "    return kmeansModel.computeCost(pipelineModel.transform(data)) / data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(60, 1.1441261032075585),\n",
       " (90, 0.6880893675555909),\n",
       " (120, 0.46846759420005024),\n",
       " (150, 0.3715874199476205),\n",
       " (180, 0.31340704586915813),\n",
       " (210, 0.26199805630434914),\n",
       " (240, 0.22810044559997783),\n",
       " (270, 0.20502721183457584)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores2 = map(lambda x: (x, clusteringScore2(numericOnly, x)) ,range(60, 271, 30))\n",
    "list(scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "def oneHotPipeline(inputCol): # (inputCol: String): (Pipeline, String)\n",
    "    indexer = StringIndexer(inputCol=inputCol, outputCol=inputCol+\"_indexed\")   \n",
    "    encoder = OneHotEncoder(inputCol=inputCol+\"_indexed\", outputCol=inputCol+\"_vec\")\n",
    "\n",
    "    pipeline = Pipeline().setStages([indexer, encoder])\n",
    "    return (pipeline, inputCol + \"_vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusteringScore3(data, k): # data: DataFrame, k: Int): Double = {\n",
    "    (protoTypeEncoder, protoTypeVecCol) = oneHotPipeline(\"protocol_type\")\n",
    "    (serviceEncoder, serviceVecCol) = oneHotPipeline(\"service\")\n",
    "    (flagEncoder, flagVecCol) = oneHotPipeline(\"flag\")\n",
    "       \n",
    "    inputCols = data.columns.copy()\n",
    "    for c in [\"protocol_type\", \"service\", \"flag\", \"label\"]:\n",
    "        inputCols.remove(c)\n",
    "    inputCols.extend([\"protocol_type_vec\", \"service_vec\", \"flag_vec\"])\n",
    "\n",
    "    assembler = VectorAssembler() \\\n",
    "        .setInputCols(inputCols) \\\n",
    "        .setOutputCol(\"featureVector\")\n",
    "    \n",
    "    scaler = StandardScaler() \\\n",
    "        .setInputCol(\"featureVector\") \\\n",
    "        .setOutputCol(\"scaledFeatureVector\") \\\n",
    "        .setWithStd(True) \\\n",
    "        .setWithMean(False)\n",
    "        \n",
    "    kmeans = KMeans() \\\n",
    "        .setSeed(42) \\\n",
    "        .setK(k) \\\n",
    "        .setMaxIter(40) \\\n",
    "        .setTol(1.0e-5) \\\n",
    "        .setPredictionCol(\"cluster\") \\\n",
    "        .setFeaturesCol(\"scaledFeatureVector\")\n",
    "    \n",
    "    pipeline = Pipeline().setStages([protoTypeEncoder, serviceEncoder, flagEncoder, assembler, scaler, kmeans])\n",
    "    pipelineModel = pipeline.fit(data)\n",
    "    kmeansModel = pipelineModel.stages[-1]\n",
    "    return kmeansModel.computeCost(pipelineModel.transform(data)) / data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(60, 34.40873843218975),\n",
       " (90, 17.395607124276115),\n",
       " (120, 2.7341559849041),\n",
       " (150, 2.073111509455972),\n",
       " (180, 1.5623811454432166),\n",
       " (210, 1.1769339814927156),\n",
       " (240, 0.9597538974191357),\n",
       " (270, 0.7760935648355177)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores3 = map(lambda x: (x, clusteringScore3(data, x)), range(60, 271, 30))\n",
    "list(scores3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Labels with Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#  Calc entropy\n",
    "#  파이썬 map은 제너레이터\n",
    "def calc_each_entropy(v, n):\n",
    "    p = v/n\n",
    "    return -p*math.log(p)\n",
    "\n",
    "def entropy(counts): # (counts: iterable[int]): Double\n",
    "    values = [x for x in counts if x > 0]\n",
    "    n = sum(map(float, values))\n",
    "    entropys = map(lambda v: calc_each_entropy(v, n), values)\n",
    "    return sum(entropys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitPipeline4(data, k):\n",
    "    (protoTypeEncoder, protoTypeVecCol) = oneHotPipeline(\"protocol_type\")\n",
    "    (serviceEncoder, serviceVecCol) = oneHotPipeline(\"service\")\n",
    "    (flagEncoder, flagVecCol) = oneHotPipeline(\"flag\")\n",
    "\n",
    "    inputCols = data.columns.copy()\n",
    "    for c in [\"protocol_type\", \"service\", \"flag\", \"label\"]:\n",
    "        inputCols.remove(c)\n",
    "    inputCols.extend([\"protocol_type_vec\", \"service_vec\", \"flag_vec\"])\n",
    "\n",
    "    assembler = VectorAssembler() \\\n",
    "        .setInputCols(inputCols) \\\n",
    "        .setOutputCol(\"featureVector\")\n",
    "    \n",
    "    scaler = StandardScaler() \\\n",
    "        .setInputCol(\"featureVector\") \\\n",
    "        .setOutputCol(\"scaledFeatureVector\") \\\n",
    "        .setWithStd(True) \\\n",
    "        .setWithMean(False)\n",
    "        \n",
    "    kmeans = KMeans() \\\n",
    "        .setSeed(42) \\\n",
    "        .setK(k) \\\n",
    "        .setMaxIter(40) \\\n",
    "        .setTol(1.0e-5) \\\n",
    "        .setPredictionCol(\"cluster\") \\\n",
    "        .setFeaturesCol(\"scaledFeatureVector\")\n",
    "    \n",
    "    pipeline = Pipeline().setStages([protoTypeEncoder, serviceEncoder, flagEncoder, assembler, scaler, kmeans])\n",
    "    return pipeline.fit(data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def clusteringScore4(data, k): # (data: DataFrame, k: Int): Double \n",
    "    pipelineModel = fitPipeline4(data, k)\n",
    "\n",
    "    clusterLabel = pipelineModel.transform(data).select([\"cluster\", \"label\"])\n",
    "    labels_grouped = clusterLabel.rdd.groupByKey()\n",
    "    labels_counted = labels_grouped.map(lambda x: (x[0], len(x[1]), list(Counter(x[1]).values())))\n",
    "    weightedClusterEntropy = labels_counted.map(lambda x: x[1]*entropy((x[2])))\n",
    "\n",
    "    # Average entropy weighted by cluster size \n",
    "    return sum(weightedClusterEntropy.collect())/data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(60, 0.15744539217936912),\n",
       " (90, 0.04303023524872978),\n",
       " (120, 0.03993253904916126),\n",
       " (150, 0.022212582441225457),\n",
       " (180, 0.015327587317161325),\n",
       " (210, 0.020206916403309093),\n",
       " (240, 0.012232202534867242),\n",
       " (270, 0.009810213344877838)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores4 = map(lambda x: (x, clusteringScore4(data, x)), range(60, 271, 30))\n",
    "list(scores4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+------+\n",
      "|cluster|           label| count|\n",
      "+-------+----------------+------+\n",
      "|      0|        neptune.| 82130|\n",
      "|      0|      portsweep.|    10|\n",
      "|      1|         normal.|     9|\n",
      "|      1|          smurf.|280773|\n",
      "|      2|        ipsweep.|     2|\n",
      "|      2|        neptune.|   105|\n",
      "|      3|        neptune.|   106|\n",
      "|      3|      portsweep.|     1|\n",
      "|      4|           imap.|     7|\n",
      "|      4|        neptune.|   105|\n",
      "|      5|        neptune.|    97|\n",
      "|      5|         normal.|     2|\n",
      "|      5|          satan.|     1|\n",
      "|      6|         normal.|  2284|\n",
      "|      7|        ipsweep.|     2|\n",
      "|      7|        neptune.|    28|\n",
      "|      7|      portsweep.|     1|\n",
      "|      8|buffer_overflow.|     1|\n",
      "|      8|        neptune.|    20|\n",
      "|      8|         normal.|     7|\n",
      "|      8|      portsweep.|     1|\n",
      "|      9|           nmap.|    23|\n",
      "|      9|         normal.|  7215|\n",
      "|      9|          satan.|    28|\n",
      "|     10|          satan.|  1220|\n",
      "|     11|        neptune.|   105|\n",
      "|     11|      portsweep.|     1|\n",
      "|     12|        neptune.|   102|\n",
      "|     12|      portsweep.|     1|\n",
      "|     12|          satan.|     1|\n",
      "|     13|         normal.|  7741|\n",
      "|     14|        neptune.|    89|\n",
      "|     14|          satan.|     1|\n",
      "|     15|         normal.|   113|\n",
      "|     15|            pod.|     1|\n",
      "|     16|        ipsweep.|     3|\n",
      "|     16|        neptune.|   112|\n",
      "|     16|      portsweep.|     1|\n",
      "|     16|          satan.|     1|\n",
      "|     17|        ipsweep.|     1|\n",
      "|     17|        neptune.|   118|\n",
      "|     17|      portsweep.|     1|\n",
      "|     18|         normal.|     1|\n",
      "|     19|        ipsweep.|    14|\n",
      "|     19|        neptune.| 19314|\n",
      "|     19|      portsweep.|    39|\n",
      "|     20|         normal.|   219|\n",
      "|     21|        neptune.|    82|\n",
      "|     22|        neptune.|    20|\n",
      "|     23|        ipsweep.|     1|\n",
      "|     23|        neptune.|   188|\n",
      "|     23|         normal.|    55|\n",
      "|     23|      portsweep.|     2|\n",
      "|     24|        neptune.|     8|\n",
      "|     24|         normal.|  4754|\n",
      "|     25|         normal.|    22|\n",
      "|     26|        ipsweep.|     1|\n",
      "|     26|        neptune.|    97|\n",
      "|     27|        neptune.|   101|\n",
      "|     27|      portsweep.|     1|\n",
      "|     28|        neptune.|    96|\n",
      "|     28|           nmap.|     1|\n",
      "|     29|           nmap.|   102|\n",
      "|     30|        neptune.|    14|\n",
      "|     31|         normal.|     2|\n",
      "|     31|            pod.|     5|\n",
      "|     32|         normal.|   380|\n",
      "|     33|        neptune.|    86|\n",
      "|     33|          satan.|     1|\n",
      "|     34|         normal.|     1|\n",
      "|     35|        neptune.|     1|\n",
      "|     35|         normal.|  2198|\n",
      "|     36|        ipsweep.|   820|\n",
      "|     36|           nmap.|    99|\n",
      "|     36|         normal.|     7|\n",
      "|     37|         normal.|    41|\n",
      "|     37|    warezclient.|   274|\n",
      "|     38|        neptune.|   113|\n",
      "|     38|      portsweep.|     2|\n",
      "|     39|buffer_overflow.|     6|\n",
      "|     39|      ftp_write.|     1|\n",
      "|     39|        ipsweep.|     3|\n",
      "|     39|       multihop.|     2|\n",
      "|     39|         normal.|  3442|\n",
      "|     39|    warezclient.|   132|\n",
      "|     39|    warezmaster.|     2|\n",
      "|     40|         normal.|   771|\n",
      "|     40|    warezclient.|     2|\n",
      "|     41|         normal.|     3|\n",
      "|     41|    warezmaster.|     1|\n",
      "|     42|        neptune.|    92|\n",
      "|     42|      portsweep.|     2|\n",
      "|     42|          satan.|     1|\n",
      "|     43|           land.|    21|\n",
      "|     43|         normal.|     1|\n",
      "|     44|         normal.|     3|\n",
      "|     45|        neptune.|   102|\n",
      "|     45|      portsweep.|     1|\n",
      "|     46|       teardrop.|   711|\n",
      "|     47|        ipsweep.|     1|\n",
      "|     47|        neptune.|   102|\n",
      "|     47|         normal.|     1|\n",
      "|     47|      portsweep.|     1|\n",
      "|     48|        neptune.|    18|\n",
      "|     48|      portsweep.|     1|\n",
      "|     49|         normal.|    33|\n",
      "|     49|          satan.|     1|\n",
      "|     50|         normal.|     2|\n",
      "|     50|    warezmaster.|    15|\n",
      "|     51|           back.|     5|\n",
      "|     51|         normal.|    17|\n",
      "|     51|          satan.|     1|\n",
      "|     51|    warezclient.|     1|\n",
      "|     52|        neptune.|   160|\n",
      "|     53|   guess_passwd.|     2|\n",
      "|     54|        ipsweep.|     2|\n",
      "|     54|        neptune.|    82|\n",
      "|     54|         normal.|    51|\n",
      "|     55|      ftp_write.|     1|\n",
      "|     55|        rootkit.|     1|\n",
      "|     56|        neptune.|   101|\n",
      "|     56|      portsweep.|     4|\n",
      "|     56|          satan.|     1|\n",
      "|     57|        neptune.|   106|\n",
      "|     58|         normal.|    65|\n",
      "|     59|        neptune.|    99|\n",
      "|     60|        neptune.|   115|\n",
      "|     61|         normal.|  1097|\n",
      "|     61|          satan.|    12|\n",
      "|     62|        neptune.|    98|\n",
      "|     62|      portsweep.|     1|\n",
      "|     63|           back.|     2|\n",
      "|     63|           imap.|     1|\n",
      "|     63|         normal.|    50|\n",
      "|     64|buffer_overflow.|     4|\n",
      "|     64|   guess_passwd.|     1|\n",
      "|     64|        ipsweep.|     1|\n",
      "|     64|     loadmodule.|     3|\n",
      "|     64|        neptune.|   177|\n",
      "|     64|         normal.|   149|\n",
      "|     64|      portsweep.|     1|\n",
      "|     64|        rootkit.|     2|\n",
      "|     64|          satan.|     1|\n",
      "|     64|            spy.|     1|\n",
      "|     65|      portsweep.|   427|\n",
      "|     66|      ftp_write.|     1|\n",
      "|     66|         normal.|     1|\n",
      "|     67|         normal.|     9|\n",
      "|     67|          satan.|     2|\n",
      "|     68|        neptune.|    25|\n",
      "|     68|      portsweep.|     4|\n",
      "|     69|         normal.|   650|\n",
      "|     70|        ipsweep.|     2|\n",
      "|     70|        neptune.|    99|\n",
      "|     70|      portsweep.|     1|\n",
      "|     71|      portsweep.|     1|\n",
      "|     72|      portsweep.|    11|\n",
      "|     73|   guess_passwd.|    45|\n",
      "|     74|         normal.|  3383|\n",
      "|     74|        rootkit.|     3|\n",
      "|     74|          satan.|    14|\n",
      "|     74|    warezclient.|     2|\n",
      "|     75|      ftp_write.|     2|\n",
      "|     75|       multihop.|     2|\n",
      "|     75|         normal.|   229|\n",
      "|     75|    warezclient.|    19|\n",
      "|     75|    warezmaster.|     1|\n",
      "|     76|        neptune.|    24|\n",
      "|     76|      portsweep.|     3|\n",
      "|     77|        neptune.|    17|\n",
      "|     78|        neptune.|   107|\n",
      "|     78|      portsweep.|     2|\n",
      "|     79|          satan.|     1|\n",
      "|     80|        neptune.|   104|\n",
      "|     80|      portsweep.|     2|\n",
      "|     80|          satan.|     1|\n",
      "|     81|           imap.|     4|\n",
      "|     82|        neptune.|   107|\n",
      "|     82|      portsweep.|     1|\n",
      "|     83|        neptune.|     5|\n",
      "|     83|         normal.|  1761|\n",
      "|     84|        neptune.|    89|\n",
      "|     85|        ipsweep.|     1|\n",
      "|     85|        neptune.|   107|\n",
      "|     85|      portsweep.|     2|\n",
      "|     86|         normal.|     5|\n",
      "|     87|        neptune.|     1|\n",
      "|     87|         normal.|   300|\n",
      "|     87|          satan.|     1|\n",
      "|     88|        neptune.|    98|\n",
      "|     89|        neptune.|    79|\n",
      "|     89|      portsweep.|     1|\n",
      "|     89|          satan.|     1|\n",
      "|     90|        neptune.|    82|\n",
      "|     91|        neptune.|   106|\n",
      "|     92|            spy.|     1|\n",
      "|     93|        neptune.|    78|\n",
      "|     94|         normal.|  3734|\n",
      "|     95|           back.|   161|\n",
      "|     95|         normal.|  2023|\n",
      "+-------+----------------+------+\n",
      "only showing top 200 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelineModel = fitPipeline4(data, 180)\n",
    "countByClusterLabel = pipelineModel.transform(data) \\\n",
    "    .select(\"cluster\", \"label\") \\\n",
    "    .groupBy(\"cluster\", \"label\").count() \\\n",
    "    .orderBy([\"cluster\", \"label\"])\n",
    "countByClusterLabel.show(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kMeansModel = pipelineModel.stages[-1]\n",
    "centroids = kMeansModel.clusterCenters()\n",
    "clustered = pipelineModel.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1897948162756258"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def sqdist(a,b):\n",
    "    return float(np.sqrt(np.sum((a-b)**2, axis=0)))\n",
    "    \n",
    "thresholds = clustered.select(\"cluster\", \"scaledFeatureVector\").rdd \\\n",
    "    .map(lambda x: sqdist(centroids[x[0]], np.array(x[1]))).take(100)\n",
    "threshold = sorted(thresholds)[99]\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5021"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = clustered.sample(0.01) # 너무 오래걸려서  1%만 샘플링\n",
    "samples.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|           label|count|\n",
      "+----------------+-----+\n",
      "|         normal.|   50|\n",
      "|        neptune.|   17|\n",
      "|           back.|    6|\n",
      "|      portsweep.|    4|\n",
      "|        ipsweep.|    2|\n",
      "|          smurf.|    1|\n",
      "|            pod.|    1|\n",
      "|buffer_overflow.|    1|\n",
      "|           nmap.|    1|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "anomalies = samples.select(\"cluster\", \"scaledFeatureVector\", \"label\").rdd \\\n",
    "    .filter(lambda x: sqdist(centroids[x[0]], np.array(x[1])) >= threshold).toDF()\n",
    "anomalies.select(\"cluster\", \"label\").groupBy('label') \\\n",
    "    .count().orderBy(\"count\", ascending=False).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
