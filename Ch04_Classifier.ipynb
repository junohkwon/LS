{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Ch04\").getOrCreate()\n",
    "spark.conf.set(\"spark.driver.memory\", \"6g\")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames = [\"Elevation\", \"Aspect\", \"Slope\",\n",
    "\"Horizontal_Distance_To_Hydrology\", \"Vertical_Distance_To_Hydrology\",\n",
    "\"Horizontal_Distance_To_Roadways\",\n",
    "\"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\",\n",
    "\"Horizontal_Distance_To_Fire_Points\"]\n",
    "for i in range(4):\n",
    "    colNames += [\"Wilderness_Area_\"+str(i),]\n",
    "for i in range(40):\n",
    "    colNames += [\"Soil_Type_\"+str(i),]\n",
    "colNames += [\"Cover_Type\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType()\n",
    "for name in colNames:\n",
    "    if name == \"Cover_Type\":\n",
    "        schema.add(StructField(name, DoubleType(), True))\n",
    "    else:\n",
    "        schema.add(StructField(name, IntegerType(), True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"covtype.data\", header=False, schema=schema)\n",
    "data = data.sample(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Elevation: integer (nullable = true)\n",
      " |-- Aspect: integer (nullable = true)\n",
      " |-- Slope: integer (nullable = true)\n",
      " |-- Horizontal_Distance_To_Hydrology: integer (nullable = true)\n",
      " |-- Vertical_Distance_To_Hydrology: integer (nullable = true)\n",
      " |-- Horizontal_Distance_To_Roadways: integer (nullable = true)\n",
      " |-- Hillshade_9am: integer (nullable = true)\n",
      " |-- Hillshade_Noon: integer (nullable = true)\n",
      " |-- Hillshade_3pm: integer (nullable = true)\n",
      " |-- Horizontal_Distance_To_Fire_Points: integer (nullable = true)\n",
      " |-- Wilderness_Area_0: integer (nullable = true)\n",
      " |-- Wilderness_Area_1: integer (nullable = true)\n",
      " |-- Wilderness_Area_2: integer (nullable = true)\n",
      " |-- Wilderness_Area_3: integer (nullable = true)\n",
      " |-- Soil_Type_0: integer (nullable = true)\n",
      " |-- Soil_Type_1: integer (nullable = true)\n",
      " |-- Soil_Type_2: integer (nullable = true)\n",
      " |-- Soil_Type_3: integer (nullable = true)\n",
      " |-- Soil_Type_4: integer (nullable = true)\n",
      " |-- Soil_Type_5: integer (nullable = true)\n",
      " |-- Soil_Type_6: integer (nullable = true)\n",
      " |-- Soil_Type_7: integer (nullable = true)\n",
      " |-- Soil_Type_8: integer (nullable = true)\n",
      " |-- Soil_Type_9: integer (nullable = true)\n",
      " |-- Soil_Type_10: integer (nullable = true)\n",
      " |-- Soil_Type_11: integer (nullable = true)\n",
      " |-- Soil_Type_12: integer (nullable = true)\n",
      " |-- Soil_Type_13: integer (nullable = true)\n",
      " |-- Soil_Type_14: integer (nullable = true)\n",
      " |-- Soil_Type_15: integer (nullable = true)\n",
      " |-- Soil_Type_16: integer (nullable = true)\n",
      " |-- Soil_Type_17: integer (nullable = true)\n",
      " |-- Soil_Type_18: integer (nullable = true)\n",
      " |-- Soil_Type_19: integer (nullable = true)\n",
      " |-- Soil_Type_20: integer (nullable = true)\n",
      " |-- Soil_Type_21: integer (nullable = true)\n",
      " |-- Soil_Type_22: integer (nullable = true)\n",
      " |-- Soil_Type_23: integer (nullable = true)\n",
      " |-- Soil_Type_24: integer (nullable = true)\n",
      " |-- Soil_Type_25: integer (nullable = true)\n",
      " |-- Soil_Type_26: integer (nullable = true)\n",
      " |-- Soil_Type_27: integer (nullable = true)\n",
      " |-- Soil_Type_28: integer (nullable = true)\n",
      " |-- Soil_Type_29: integer (nullable = true)\n",
      " |-- Soil_Type_30: integer (nullable = true)\n",
      " |-- Soil_Type_31: integer (nullable = true)\n",
      " |-- Soil_Type_32: integer (nullable = true)\n",
      " |-- Soil_Type_33: integer (nullable = true)\n",
      " |-- Soil_Type_34: integer (nullable = true)\n",
      " |-- Soil_Type_35: integer (nullable = true)\n",
      " |-- Soil_Type_36: integer (nullable = true)\n",
      " |-- Soil_Type_37: integer (nullable = true)\n",
      " |-- Soil_Type_38: integer (nullable = true)\n",
      " |-- Soil_Type_39: integer (nullable = true)\n",
      " |-- Cover_Type: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Elevation=2596, Aspect=51, Slope=3, Horizontal_Distance_To_Hydrology=258, Vertical_Distance_To_Hydrology=0, Horizontal_Distance_To_Roadways=510, Hillshade_9am=221, Hillshade_Noon=232, Hillshade_3pm=148, Horizontal_Distance_To_Fire_Points=6279, Wilderness_Area_0=1, Wilderness_Area_1=0, Wilderness_Area_2=0, Wilderness_Area_3=0, Soil_Type_0=0, Soil_Type_1=0, Soil_Type_2=0, Soil_Type_3=0, Soil_Type_4=0, Soil_Type_5=0, Soil_Type_6=0, Soil_Type_7=0, Soil_Type_8=0, Soil_Type_9=0, Soil_Type_10=0, Soil_Type_11=0, Soil_Type_12=0, Soil_Type_13=0, Soil_Type_14=0, Soil_Type_15=0, Soil_Type_16=0, Soil_Type_17=0, Soil_Type_18=0, Soil_Type_19=0, Soil_Type_20=0, Soil_Type_21=0, Soil_Type_22=0, Soil_Type_23=0, Soil_Type_24=0, Soil_Type_25=0, Soil_Type_26=0, Soil_Type_27=0, Soil_Type_28=1, Soil_Type_29=0, Soil_Type_30=0, Soil_Type_31=0, Soil_Type_32=0, Soil_Type_33=0, Soil_Type_34=0, Soil_Type_35=0, Soil_Type_36=0, Soil_Type_37=0, Soil_Type_38=0, Soil_Type_39=0, Cover_Type=5.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainData, testData) = data.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputCols = trainData.drop('Cover_Type').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|featureVector                                                                                        |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1863.0,37.0,17.0,120.0,18.0,90.0,217.0,202.0,115.0,769.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,5,6,7,8,9,13,18],[1874.0,18.0,14.0,90.0,208.0,209.0,135.0,793.0,1.0,1.0])                 |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1888.0,33.0,22.0,150.0,46.0,108.0,209.0,185.0,103.0,735.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1889.0,28.0,22.0,150.0,23.0,120.0,205.0,185.0,108.0,759.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1889.0,353.0,30.0,95.0,39.0,67.0,153.0,172.0,146.0,600.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1899.0,355.0,22.0,153.0,43.0,124.0,178.0,195.0,151.0,819.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1901.0,311.0,9.0,30.0,2.0,190.0,195.0,234.0,179.0,726.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1904.0,51.0,26.0,67.0,30.0,162.0,222.0,175.0,72.0,711.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1905.0,19.0,27.0,134.0,58.0,120.0,188.0,171.0,108.0,636.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,16],[1905.0,77.0,21.0,90.0,38.0,120.0,241.0,196.0,75.0,1025.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1908.0,323.0,32.0,150.0,52.0,120.0,125.0,190.0,196.0,765.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1916.0,24.0,25.0,212.0,74.0,175.0,197.0,177.0,105.0,789.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1916.0,320.0,24.0,190.0,60.0,162.0,151.0,210.0,195.0,832.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,23],[1918.0,321.0,28.0,42.0,17.0,85.0,139.0,201.0,196.0,402.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1919.0,30.0,22.0,67.0,9.0,256.0,208.0,188.0,107.0,661.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1925.0,352.0,22.0,210.0,74.0,182.0,176.0,197.0,155.0,779.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1927.0,4.0,36.0,120.0,78.0,95.0,149.0,147.0,116.0,666.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1927.0,54.0,25.0,190.0,76.0,175.0,225.0,177.0,71.0,735.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1927.0,333.0,27.0,218.0,72.0,190.0,149.0,195.0,180.0,859.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,16],[1929.0,172.0,16.0,90.0,30.0,108.0,229.0,246.0,143.0,787.0,1.0,1.0]) |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=inputCols,\n",
    "    outputCol=\"featureVector\")\n",
    "assembledTrainData = assembler.transform(trainData)\n",
    "assembledTrainData.select('featureVector').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4488a1c40919b13b7cb8) of depth 5 with 63 nodes\n",
      "  If (feature 0 <= 3052.5)\n",
      "   If (feature 0 <= 2564.5)\n",
      "    If (feature 10 <= 0.5)\n",
      "     If (feature 0 <= 2457.5)\n",
      "      If (feature 3 <= 15.0)\n",
      "       Predict: 4.0\n",
      "      Else (feature 3 > 15.0)\n",
      "       Predict: 3.0\n",
      "     Else (feature 0 > 2457.5)\n",
      "      If (feature 17 <= 0.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 17 > 0.5)\n",
      "       Predict: 3.0\n",
      "    Else (feature 10 > 0.5)\n",
      "     If (feature 9 <= 5474.5)\n",
      "      If (feature 22 <= 0.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 22 > 0.5)\n",
      "       Predict: 2.0\n",
      "     Else (feature 9 > 5474.5)\n",
      "      If (feature 5 <= 567.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 5 > 567.5)\n",
      "       Predict: 5.0\n",
      "   Else (feature 0 > 2564.5)\n",
      "    If (feature 0 <= 2957.5)\n",
      "     If (feature 15 <= 0.5)\n",
      "      If (feature 17 <= 0.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 17 > 0.5)\n",
      "       Predict: 3.0\n",
      "     Else (feature 15 > 0.5)\n",
      "      If (feature 9 <= 1358.5)\n",
      "       Predict: 3.0\n",
      "      Else (feature 9 > 1358.5)\n",
      "       Predict: 3.0\n",
      "    Else (feature 0 > 2957.5)\n",
      "     If (feature 3 <= 211.0)\n",
      "      If (feature 36 <= 0.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 36 > 0.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 3 > 211.0)\n",
      "      If (feature 7 <= 218.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 7 > 218.5)\n",
      "       Predict: 2.0\n",
      "  Else (feature 0 > 3052.5)\n",
      "   If (feature 0 <= 3306.5)\n",
      "    If (feature 7 <= 240.5)\n",
      "     If (feature 45 <= 0.5)\n",
      "      If (feature 42 <= 0.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 42 > 0.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 45 > 0.5)\n",
      "      If (feature 5 <= 4152.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 5 > 4152.5)\n",
      "       Predict: 1.0\n",
      "    Else (feature 7 > 240.5)\n",
      "     If (feature 3 <= 316.0)\n",
      "      If (feature 0 <= 3202.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 0 > 3202.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 3 > 316.0)\n",
      "      If (feature 0 <= 3202.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 0 > 3202.5)\n",
      "       Predict: 2.0\n",
      "   Else (feature 0 > 3306.5)\n",
      "    If (feature 12 <= 0.5)\n",
      "     If (feature 4 <= 33.5)\n",
      "      If (feature 3 <= 296.0)\n",
      "       Predict: 7.0\n",
      "      Else (feature 3 > 296.0)\n",
      "       Predict: 1.0\n",
      "     Else (feature 4 > 33.5)\n",
      "      If (feature 10 <= 0.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 10 > 0.5)\n",
      "       Predict: 1.0\n",
      "    Else (feature 12 > 0.5)\n",
      "     If (feature 45 <= 0.5)\n",
      "      If (feature 0 <= 3366.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 0 > 3366.5)\n",
      "       Predict: 7.0\n",
      "     Else (feature 45 > 0.5)\n",
      "      If (feature 5 <= 1000.0)\n",
      "       Predict: 7.0\n",
      "      Else (feature 5 > 1000.0)\n",
      "       Predict: 1.0\n",
      "\n",
      "(54,[0,3,4,5,7,9,10,12,15,17,22,36,42,45],[0.7812468572578319,0.03741563479117538,0.0032527114572553743,0.005897715887558074,0.03091138836761956,0.0017319060395040884,0.035298831368034446,0.011093960455724786,0.022207883417732735,0.02917703165751734,0.0003390974135918236,0.00570456281600033,0.009372037982683764,0.026350381087770477])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(labelCol=\"Cover_Type\", featuresCol=\"featureVector\", predictionCol=\"prediction\")\n",
    "model = classifier.fit(assembledTrainData)\n",
    "\n",
    "print(model.toDebugString)\n",
    "print(model.featureImportances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------------------------------------------------------------------------------------+\n",
      "|Cover_Type|prediction|probability                                                                                    |\n",
      "+----------+----------+-----------------------------------------------------------------------------------------------+\n",
      "|6.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|6.0       |4.0       |[0.0,0.0,0.0440251572327044,0.2893081761006289,0.41949685534591197,0.0,0.24716981132075472,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|3.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|3.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "|3.0       |3.0       |[0.0,0.0,0.03713489623366641,0.6286510376633359,0.04900076863950807,0.0,0.2852132974634896,0.0]|\n",
      "+----------+----------+-----------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(assembledTrainData)\n",
    "predictions.select([\"Cover_Type\", \"prediction\", \"probability\"]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Cover_Type\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6996838662393209"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.setMetricName(\"accuracy\").evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6815291039582252"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.setMetricName(\"f1\").evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### confusion matrix - not supported in PySpark ML library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "inputCols = trainData.columns[:-1]\n",
    "assembler = VectorAssembler(inputCols=inputCols, outputCol=\"featureVector\")\n",
    "classifier = DecisionTreeClassifier(labelCol=\"Cover_Type\", featuresCol=\"featureVector\", predictionCol=\"prediction\")\n",
    "pipeline = Pipeline(stages=[assembler, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(classifier.impurity, [\"gini\", \"entropy\"])\\\n",
    "    .addGrid(classifier.maxDepth, [10, 30])\\\n",
    "    .addGrid(classifier.maxBins, [40, 100])\\\n",
    "    .addGrid(classifier.minInfoGain, [0.0, 0.05])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6996838662393209"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclassEval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Cover_Type\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\")\n",
    "multiclassEval.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "\n",
    "validator = TrainValidationSplit(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=multiclassEval,\n",
    "    trainRatio=0.9)\n",
    "validatorModel = validator.fit(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = validatorModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='DecisionTreeClassifier_43ebb083a9c3637b52c0', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees.'): False,\n",
       " Param(parent='DecisionTreeClassifier_43ebb083a9c3637b52c0', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext'): 10,\n",
       " Param(parent='DecisionTreeClassifier_43ebb083a9c3637b52c0', name='featuresCol', doc='features column name'): 'featureVector',\n",
       " Param(parent='DecisionTreeClassifier_43ebb083a9c3637b52c0', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       " Param(parent='DecisionTreeClassifier_43ebb083a9c3637b52c0', name='labelCol', doc='label column name'): 'Cover_Type',\n",
       " Param(parent='DecisionTreeClassifier_43ebb083a9c3637b52c0', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 100,\n",
       " Param(parent='DecisionTreeClassifier_43ebb083a9c3637b52c0', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       " Param(parent='DecisionTreeClassifier_43ebb083a9c3637b52c0', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation.'): 256,\n",
       " Param(parent='DecisionTreeClassifier_43ebb083a9c3637b52c0', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0,\n",
       " Param(parent='DecisionTreeClassifier_43ebb083a9c3637b52c0', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split.  If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1,\n",
       " Param(parent='DecisionTreeClassifier_43ebb083a9c3637b52c0', name='predictionCol', doc='prediction column name'): 'prediction',\n",
       " Param(parent='DecisionTreeClassifier_43ebb083a9c3637b52c0', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities'): 'probability',\n",
       " Param(parent='DecisionTreeClassifier_43ebb083a9c3637b52c0', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name'): 'rawPrediction',\n",
       " Param(parent='DecisionTreeClassifier_43ebb083a9c3637b52c0', name='seed', doc='random seed'): -2215042765462860379}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.stages[-1].extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6311497480478516,\n",
       " 0.6311497480478516,\n",
       " 0.6318806016078778,\n",
       " 0.6318806016078778,\n",
       " 0.7713582336423433,\n",
       " 0.6671154363965073,\n",
       " 0.776358810631996,\n",
       " 0.666846174558603,\n",
       " 0.4862868792552987,\n",
       " 0.4862868792552987,\n",
       " 0.4862868792552987,\n",
       " 0.4862868792552987,\n",
       " 0.7724352809939609,\n",
       " 0.7143516559603031,\n",
       " 0.7706658460591607,\n",
       " 0.7107358541370158]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramsAndMetrics = validatorModel.validationMetrics\n",
    "paramsAndMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7791275538376587"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclassEval.evaluate(bestModel.transform(testData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### undoing the one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildernessCols = []\n",
    "for i in range(4):\n",
    "    wildernessCols += [\"Wilderness_Area_\"+str(i),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildernessAssembler = VectorAssembler(\n",
    "    inputCols=wildernessCols,\n",
    "    outputCol=\"wilderness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, DoubleType, StructType\n",
    "\n",
    "unhotudf = udf(lambda x: float(x.toArray().nonzero()[0]), DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Elevation=2596, Aspect=51, Slope=3, Horizontal_Distance_To_Hydrology=258, Vertical_Distance_To_Hydrology=0, Horizontal_Distance_To_Roadways=510, Hillshade_9am=221, Hillshade_Noon=232, Hillshade_3pm=148, Horizontal_Distance_To_Fire_Points=6279, Soil_Type_0=0, Soil_Type_1=0, Soil_Type_2=0, Soil_Type_3=0, Soil_Type_4=0, Soil_Type_5=0, Soil_Type_6=0, Soil_Type_7=0, Soil_Type_8=0, Soil_Type_9=0, Soil_Type_10=0, Soil_Type_11=0, Soil_Type_12=0, Soil_Type_13=0, Soil_Type_14=0, Soil_Type_15=0, Soil_Type_16=0, Soil_Type_17=0, Soil_Type_18=0, Soil_Type_19=0, Soil_Type_20=0, Soil_Type_21=0, Soil_Type_22=0, Soil_Type_23=0, Soil_Type_24=0, Soil_Type_25=0, Soil_Type_26=0, Soil_Type_27=0, Soil_Type_28=1, Soil_Type_29=0, Soil_Type_30=0, Soil_Type_31=0, Soil_Type_32=0, Soil_Type_33=0, Soil_Type_34=0, Soil_Type_35=0, Soil_Type_36=0, Soil_Type_37=0, Soil_Type_38=0, Soil_Type_39=0, Cover_Type=5.0, wilderness=0.0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withWilderness = wildernessAssembler.transform(data)\n",
    "withWilderness = withWilderness\\\n",
    "    .drop(*wildernessCols)\\\n",
    "    .withColumn(\"wilderness\", unhotudf(withWilderness['wilderness']))\n",
    "withWilderness.take(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soilCols = []\n",
    "for i in range(40):\n",
    "    soilCols += [\"Soil_Type_\"+str(i),]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Elevation=2596, Aspect=51, Slope=3, Horizontal_Distance_To_Hydrology=258, Vertical_Distance_To_Hydrology=0, Horizontal_Distance_To_Roadways=510, Hillshade_9am=221, Hillshade_Noon=232, Hillshade_3pm=148, Horizontal_Distance_To_Fire_Points=6279, Cover_Type=5.0, wilderness=0.0, soil=28.0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soilAssembler = VectorAssembler(\n",
    "        inputCols=soilCols,\n",
    "        outputCol=\"soil\")\n",
    "\n",
    "withWilderness = soilAssembler.transform(withWilderness)\n",
    "unencData = withWilderness\\\n",
    "    .drop(*soilCols)\\\n",
    "    .withColumn(\"soil\", unhotudf(withWilderness['soil']))\n",
    "unencData.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier with unencoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unencTrainData, unencTestData) = unencData.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorIndexer\n",
    "\n",
    "inputCols = unencTrainData.drop('Cover_Type').columns\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=inputCols,\n",
    "    outputCol=\"featureVector\")\n",
    "indexer = VectorIndexer(\n",
    "    maxCategories=40,\n",
    "    inputCol=\"featureVector\",\n",
    "    outputCol=\"indexedVector\")\n",
    "classifier = DecisionTreeClassifier(\n",
    "    seed=42,\n",
    "    labelCol=\"Cover_Type\",\n",
    "    featuresCol=\"indexedVector\",\n",
    "    predictionCol=\"prediction\")\n",
    "pipeline = Pipeline(stages=[assembler, indexer, classifier])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(\n",
    "    seed=42,\n",
    "    maxBins=40,\n",
    "    labelCol=\"Cover_Type\",\n",
    "    featuresCol=\"indexedVector\",\n",
    "    predictionCol=\"prediction\")\n",
    "pipeline = Pipeline(stages=[assembler, indexer, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(classifier.minInfoGain, [0.0, 0.05])\\\n",
    "    .addGrid(classifier.numTrees, [1, 10])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclassEval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Cover_Type\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = TrainValidationSplit(\n",
    "    seed=42,\n",
    "    estimator=pipeline,\n",
    "    evaluator=multiclassEval,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    trainRatio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Param(parent='RandomForestClassifier_45f0a81119d63d49cad3', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees.'): False, Param(parent='RandomForestClassifier_45f0a81119d63d49cad3', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext'): 10, Param(parent='RandomForestClassifier_45f0a81119d63d49cad3', name='featureSubsetStrategy', doc='The number of features to consider for splits at each tree node. Supported options: auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n].'): 'auto', Param(parent='RandomForestClassifier_45f0a81119d63d49cad3', name='featuresCol', doc='features column name'): 'indexedVector', Param(parent='RandomForestClassifier_45f0a81119d63d49cad3', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini', Param(parent='RandomForestClassifier_45f0a81119d63d49cad3', name='labelCol', doc='label column name'): 'Cover_Type', Param(parent='RandomForestClassifier_45f0a81119d63d49cad3', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40, Param(parent='RandomForestClassifier_45f0a81119d63d49cad3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='RandomForestClassifier_45f0a81119d63d49cad3', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation.'): 256, Param(parent='RandomForestClassifier_45f0a81119d63d49cad3', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0, Param(parent='RandomForestClassifier_45f0a81119d63d49cad3', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split.  If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='RandomForestClassifier_45f0a81119d63d49cad3', name='numTrees', doc='Number of trees to train (>= 1)'): 1, Param(parent='RandomForestClassifier_45f0a81119d63d49cad3', name='predictionCol', doc='prediction column name'): 'prediction', Param(parent='RandomForestClassifier_45f0a81119d63d49cad3', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities'): 'probability', Param(parent='RandomForestClassifier_45f0a81119d63d49cad3', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name'): 'rawPrediction', Param(parent='RandomForestClassifier_45f0a81119d63d49cad3', name='seed', doc='random seed'): 42, Param(parent='RandomForestClassifier_45f0a81119d63d49cad3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "validatorModel = validator.fit(unencTrainData)\n",
    "bestModel = validatorModel.bestModel\n",
    "forestModel = bestModel.stages[-1]\n",
    "print(forestModel.extractParamMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forestModel.getNumTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Elevation', 0.7860025044296983),\n",
       " ('soil', 0.09116264744099219),\n",
       " ('wilderness', 0.05172368780227767),\n",
       " ('Horizontal_Distance_To_Roadways', 0.026353854899294458),\n",
       " ('Horizontal_Distance_To_Hydrology', 0.017894174809860053),\n",
       " ('Horizontal_Distance_To_Fire_Points', 0.013144739584476843),\n",
       " ('Hillshade_Noon', 0.01305765636783883),\n",
       " ('Slope', 0.0006607346655616949),\n",
       " ('Aspect', 0.0),\n",
       " ('Vertical_Distance_To_Hydrology', 0.0),\n",
       " ('Hillshade_9am', 0.0),\n",
       " ('Hillshade_3pm', 0.0)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(inputCols, forestModel.featureImportances)), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6960249682751998"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testAccuracy = multiclassEval.evaluate(bestModel.transform(unencTestData))\n",
    "testAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-----+--------------------------------+------------------------------+-------------------------------+-------------+--------------+-------------+----------------------------------+----------+----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|Elevation|Aspect|Slope|Horizontal_Distance_To_Hydrology|Vertical_Distance_To_Hydrology|Horizontal_Distance_To_Roadways|Hillshade_9am|Hillshade_Noon|Hillshade_3pm|Horizontal_Distance_To_Fire_Points|wilderness|soil|       featureVector|       indexedVector|       rawPrediction|         probability|prediction|\n",
      "+---------+------+-----+--------------------------------+------------------------------+-------------------------------+-------------+--------------+-------------+----------------------------------+----------+----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|     1879|    28|   19|                              30|                            12|                             95|          209|           196|          117|                               778|       3.0| 4.0|[1879.0,28.0,19.0...|[1879.0,28.0,19.0...|[0.0,0.0,0.029617...|[0.0,0.0,0.029617...|       3.0|\n",
      "|     1939|   153|   18|                             134|                            40|                            153|          239|           238|          122|                               800|       3.0| 2.0|[1939.0,153.0,18....|[1939.0,153.0,18....|[0.0,0.0,0.029617...|[0.0,0.0,0.029617...|       3.0|\n",
      "|     1978|   346|   37|                             134|                            91|                            150|          124|           154|          151|                               108|       3.0| 9.0|[1978.0,346.0,37....|[1978.0,346.0,37....|[0.0,0.0,0.042282...|[0.0,0.0,0.042282...|       3.0|\n",
      "|     2004|   340|   38|                             108|                            77|                            124|          117|           158|          163|                               708|       3.0| 9.0|[2004.0,340.0,38....|[2004.0,340.0,38....|[0.0,0.0,0.042282...|[0.0,0.0,0.042282...|       3.0|\n",
      "|     2009|   128|   14|                               0|                             0|                            270|          243|           230|          113|                               313|       3.0| 5.0|[2009.0,128.0,14....|[2009.0,128.0,14....|[0.0,0.0,0.131034...|[0.0,0.0,0.131034...|       3.0|\n",
      "|     2011|     8|   15|                              30|                             2|                            240|          202|           209|          143|                               295|       3.0|13.0|[2011.0,8.0,15.0,...|[2011.0,8.0,15.0,...|[0.0,0.0,0.029617...|[0.0,0.0,0.029617...|       3.0|\n",
      "|     2011|    67|   37|                             153|                           103|                            190|          228|           141|           12|                               524|       3.0| 0.0|[2011.0,67.0,37.0...|[2011.0,67.0,37.0...|[0.0,0.0,0.029617...|[0.0,0.0,0.029617...|       3.0|\n",
      "|     2015|    93|   12|                               0|                             0|                            330|          239|           222|          111|                               402|       3.0|13.0|[2015.0,93.0,12.0...|[2015.0,93.0,12.0...|[0.0,0.0,0.012110...|[0.0,0.0,0.012110...|       4.0|\n",
      "|     2020|   358|   25|                               0|                             0|                            531|          174|           186|          143|                               511|       3.0| 9.0|[2020.0,358.0,25....|[2020.0,358.0,25....|[0.0,0.0,0.131034...|[0.0,0.0,0.131034...|       3.0|\n",
      "|     2022|    19|   14|                              30|                             6|                            446|          209|           210|          136|                               495|       3.0| 9.0|[2022.0,19.0,14.0...|[2022.0,19.0,14.0...|[0.0,0.0,0.042282...|[0.0,0.0,0.042282...|       3.0|\n",
      "|     2029|    61|   27|                              30|                            26|                            240|          230|           173|           58|                               443|       3.0| 2.0|[2029.0,61.0,27.0...|[2029.0,61.0,27.0...|[0.0,0.0,0.029617...|[0.0,0.0,0.029617...|       3.0|\n",
      "|     2029|   336|   30|                               0|                             0|                            573|          140|           185|          175|                               511|       3.0| 9.0|[2029.0,336.0,30....|[2029.0,336.0,30....|[0.0,0.0,0.131034...|[0.0,0.0,0.131034...|       3.0|\n",
      "|     2035|   281|   28|                              30|                            12|                            430|          133|           230|          230|                               674|       3.0| 9.0|[2035.0,281.0,28....|[2035.0,281.0,28....|[0.0,0.0,0.042282...|[0.0,0.0,0.042282...|       3.0|\n",
      "|     2037|    29|   24|                               0|                             0|                            582|          204|           182|          104|                               485|       3.0| 9.0|[2037.0,29.0,24.0...|[2037.0,29.0,24.0...|[0.0,0.0,0.131034...|[0.0,0.0,0.131034...|       3.0|\n",
      "|     2039|   267|   15|                              30|                             0|                            450|          180|           245|          204|                               633|       3.0|16.0|[2039.0,267.0,15....|[2039.0,267.0,15....|[0.0,0.0,0.042282...|[0.0,0.0,0.042282...|       3.0|\n",
      "|     2047|    31|   21|                             216|                            54|                            272|          210|           190|          109|                               277|       3.0| 4.0|[2047.0,31.0,21.0...|[2047.0,31.0,21.0...|[0.0,0.0,0.029617...|[0.0,0.0,0.029617...|       3.0|\n",
      "|     2052|    29|   16|                               0|                             0|                            942|          213|           204|          123|                               510|       3.0|16.0|[2052.0,29.0,16.0...|[2052.0,29.0,16.0...|[0.0,0.0,0.012110...|[0.0,0.0,0.012110...|       4.0|\n",
      "|     2059|   340|   18|                              95|                            56|                            150|          178|           210|          169|                               731|       3.0| 9.0|[2059.0,340.0,18....|[2059.0,340.0,18....|[0.0,0.0,0.042282...|[0.0,0.0,0.042282...|       3.0|\n",
      "|     2061|    46|   31|                             108|                            66|                            180|          212|           157|           58|                               342|       3.0| 9.0|[2061.0,46.0,31.0...|[2061.0,46.0,31.0...|[0.0,0.0,0.042282...|[0.0,0.0,0.042282...|       3.0|\n",
      "|     2062|   259|   21|                              95|                            35|                            497|          166|           247|          216|                               469|       3.0| 0.0|[2062.0,259.0,21....|[2062.0,259.0,21....|[0.0,0.0,0.029617...|[0.0,0.0,0.029617...|       3.0|\n",
      "+---------+------+-----+--------------------------------+------------------------------+-------------------------------+-------------+--------------+-------------+----------------------------------+----------+----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestModel.transform(unencTestData.drop(\"Cover_Type\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|featureVector                                                                                        |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1879.0,28.0,19.0,30.0,12.0,95.0,209.0,196.0,117.0,778.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1888.0,33.0,22.0,150.0,46.0,108.0,209.0,185.0,103.0,735.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1901.0,311.0,9.0,30.0,2.0,190.0,195.0,234.0,179.0,726.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1903.0,5.0,13.0,42.0,4.0,201.0,203.0,214.0,148.0,708.0,1.0,1.0])    |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,16],[1903.0,67.0,16.0,108.0,36.0,120.0,234.0,207.0,100.0,969.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1904.0,51.0,26.0,67.0,30.0,162.0,222.0,175.0,72.0,711.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1905.0,33.0,27.0,90.0,46.0,150.0,204.0,171.0,89.0,725.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1906.0,356.0,20.0,150.0,55.0,120.0,184.0,201.0,151.0,726.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1908.0,323.0,32.0,150.0,52.0,120.0,125.0,190.0,196.0,765.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1916.0,24.0,25.0,212.0,74.0,175.0,197.0,177.0,105.0,789.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1919.0,44.0,26.0,162.0,68.0,150.0,216.0,173.0,77.0,706.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1927.0,54.0,25.0,190.0,76.0,175.0,225.0,177.0,71.0,735.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1928.0,252.0,31.0,30.0,14.0,180.0,138.0,243.0,233.0,765.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,16],[1936.0,163.0,13.0,120.0,37.0,127.0,232.0,243.0,140.0,816.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,16],[1939.0,153.0,18.0,134.0,40.0,153.0,239.0,238.0,122.0,800.0,1.0,1.0])|\n",
      "|(54,[0,1,2,5,6,7,8,9,13,23],[1944.0,33.0,22.0,30.0,210.0,187.0,104.0,277.0,1.0,1.0])                 |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1944.0,339.0,30.0,240.0,93.0,210.0,142.0,181.0,169.0,815.0,1.0,1.0])|\n",
      "|(54,[0,1,2,5,6,7,8,9,13,14],[1946.0,319.0,17.0,360.0,175.0,222.0,187.0,642.0,1.0,1.0])               |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1949.0,347.0,22.0,60.0,28.0,330.0,173.0,199.0,161.0,708.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1954.0,47.0,32.0,218.0,99.0,210.0,213.0,155.0,55.0,927.0,1.0,1.0])  |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Cover_Type|prediction|probability                                                                                                                                                               |\n",
      "+----------+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|6.0       |3.0       |[4.9629716925263696E-8,1.2746453615734883E-6,1.0459302446367671E-4,0.5577229061523565,0.03369483985437012,1.9035434746649002E-4,0.40828550436063504,4.779856295538405E-7] |\n",
      "|6.0       |3.0       |[4.4987138234227674E-8,1.2304672966921175E-7,0.003071236540101987,0.897480755699046,0.04323923386223377,5.600775191804382E-4,0.05564842674846145,1.0159710847833949E-7]   |\n",
      "|6.0       |3.0       |[4.5037756936691296E-8,9.182887054796208E-7,7.75828871646537E-5,0.6010310256991411,0.07035232072490473,2.260709268053937E-4,0.32831181475034177,2.2168518002919914E-7]    |\n",
      "|6.0       |3.0       |[6.919075333936566E-8,2.462659897156671E-6,1.651930337129469E-4,0.539683092377891,0.10902193315857893,1.7924757710056615E-4,0.350947356059463,6.459426032211322E-7]       |\n",
      "|3.0       |3.0       |[4.752135551438821E-8,2.1322708249328897E-7,0.015704494580334436,0.5041341993937252,0.455790105738971,3.204595125610491E-5,0.024338775659778412,1.1792749674296328E-7]    |\n",
      "|6.0       |3.0       |[5.286816793834828E-8,1.3863907720084646E-6,5.7776688845509534E-5,0.691786090241345,0.10470063863831418,1.596957927245211E-4,0.20329360357444218,7.558053888854984E-7]    |\n",
      "|6.0       |3.0       |[6.36064718177265E-8,2.4783033082569582E-6,8.545810741086404E-5,0.6765663497521974,0.08159309125275663,1.5147503608914213E-4,0.24159988360092907,1.2003408367436624E-6]   |\n",
      "|6.0       |3.0       |[3.120410914920377E-8,6.968211324382472E-8,0.0018083307468139624,0.9215218665721345,0.01888504872274667,6.227376418431978E-4,0.05716186851722161,4.69130176571718E-8]     |\n",
      "|6.0       |3.0       |[3.07840083955349E-8,2.3265160753416093E-6,9.670822220661674E-5,0.6206844556376573,0.003091566541843353,9.214822480446031E-5,0.3760325494133816,2.1466002285772112E-7]    |\n",
      "|6.0       |3.0       |[5.259484192405209E-8,2.2968672247027768E-7,0.0038976609834364133,0.9090014012841666,0.031605437988296466,5.399781457674917E-4,0.054955059640048966,1.7967671983163353E-7]|\n",
      "|6.0       |3.0       |[5.008975095706729E-8,1.466901551291297E-6,7.937895462815185E-5,0.7054929656656453,0.02592020612226511,2.075378502561294E-4,0.2682975732085324,8.212073705986232E-7]      |\n",
      "|6.0       |3.0       |[5.134291106116074E-8,1.3125207124228298E-6,6.268857185112659E-5,0.7574942372295254,0.08181063418051082,1.8738552074363418E-4,0.16044292812671784,7.625070279060779E-7]   |\n",
      "|6.0       |3.0       |[1.5162964598048277E-8,6.017191272440737E-7,5.4327005307993537E-5,0.7536820187283403,0.00802553900825951,6.532075812821889E-5,0.2381721697221325,7.895739504345317E-9]    |\n",
      "|3.0       |3.0       |[3.0376513990111445E-8,9.095250258051242E-8,0.012151485383488128,0.6622238392290373,0.30263067711174635,3.819931571675111E-5,0.02295566091668493,1.6714310009326765E-8]   |\n",
      "|3.0       |3.0       |[2.23525971466923E-8,5.516746791345009E-8,0.008254974543826475,0.7251791870518947,0.2493797050548759,3.151179642671328E-5,0.01715453553025263,8.502658581893705E-9]       |\n",
      "|3.0       |3.0       |[1.5364822936525446E-7,1.9955951948712316E-5,0.02772578793992456,0.7185000291172927,0.021976587178410487,4.4863921614326916E-4,0.23132856832882995,2.7861922111110846E-7] |\n",
      "|6.0       |3.0       |[4.080010659877694E-8,2.9275180899189513E-6,1.0286773105431839E-4,0.6631991325620967,0.004124343648230131,1.3870006272158336E-4,0.3324313808080436,6.068696571510966E-7]  |\n",
      "|6.0       |3.0       |[4.707270104023229E-8,1.6749930155931874E-6,9.030697718163353E-5,0.5867384930194436,0.042810173129415596,1.6467292754392628E-4,0.370194345092661,2.867880376695769E-7]    |\n",
      "|6.0       |3.0       |[5.320408534885898E-8,2.2308887617104903E-6,8.035240245509786E-5,0.6373684650959942,0.037972169182447585,1.6669205903812185E-4,0.324409387954121,6.492130970627417E-7]    |\n",
      "|6.0       |3.0       |[6.645584919684961E-8,3.0225963783455304E-6,7.043187415201528E-5,0.7652372268852291,0.06592911222823854,1.7351496779687548E-4,0.1685844238318797,2.2011604761008016E-6]   |\n",
      "+----------+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(trainData, testData) = data.randomSplit([0.9, 0.1])\n",
    "\n",
    "inputCols = trainData.drop('Cover_Type').columns\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=inputCols,\n",
    "    outputCol=\"featureVector\")\n",
    "assembledTrainData = assembler.transform(trainData)\n",
    "assembledTrainData.select('featureVector').show(truncate=False)\n",
    "\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "classifier = LogisticRegression(labelCol=\"Cover_Type\", featuresCol=\"featureVector\", predictionCol=\"prediction\")\n",
    "model = classifier.fit(assembledTrainData)\n",
    "\n",
    "#print(model.toDebugString)\n",
    "#print(model.featureImportances)\n",
    "\n",
    "predictions = model.transform(assembledTrainData)\n",
    "predictions.select([\"Cover_Type\", \"prediction\", \"probability\"]).show(truncate=False)\n",
    "\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Cover_Type\", predictionCol=\"prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7000832675657908"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.setMetricName(\"accuracy\").evaluate(predictions)\n",
    "evaluator.setMetricName(\"f1\").evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - ParamGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(classifier.regParam, [0.1, 0.2])\\\n",
    "    .addGrid(classifier.elasticNetParam, [0.001, 0.01])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclassEval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Cover_Type\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = TrainValidationSplit(\n",
    "    estimator=pipeline,\n",
    "    evaluator=multiclassEval,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    trainRatio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "validatorModel = validator.fit(unencTrainData)\n",
    "bestModel = validatorModel.bestModel\n",
    "forestModel = bestModel.stages[-1]\n",
    "print(forestModel.extractParamMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAccuracy = multiclassEval.evaluate(bestModel.transform(unencTestData))\n",
    "testAccuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
