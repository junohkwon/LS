{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Ch04\").getOrCreate()\n",
    "spark.conf.set(\"spark.driver.memory\", \"6g\")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames = [\"Elevation\", \"Aspect\", \"Slope\",\n",
    "\"Horizontal_Distance_To_Hydrology\", \"Vertical_Distance_To_Hydrology\",\n",
    "\"Horizontal_Distance_To_Roadways\",\n",
    "\"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\",\n",
    "\"Horizontal_Distance_To_Fire_Points\"]\n",
    "for i in range(4):\n",
    "    colNames += [\"Wilderness_Area_\"+str(i),]\n",
    "for i in range(40):\n",
    "    colNames += [\"Soil_Type_\"+str(i),]\n",
    "colNames += [\"Cover_Type\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType()\n",
    "for name in colNames:\n",
    "    if name == \"Cover_Type\":\n",
    "        schema.add(StructField(name, DoubleType(), True))\n",
    "    else:\n",
    "        schema.add(StructField(name, IntegerType(), True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"./data/covtype.data\", header=False, schema=schema)\n",
    "data = data.sample(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Elevation: integer (nullable = true)\n",
      " |-- Aspect: integer (nullable = true)\n",
      " |-- Slope: integer (nullable = true)\n",
      " |-- Horizontal_Distance_To_Hydrology: integer (nullable = true)\n",
      " |-- Vertical_Distance_To_Hydrology: integer (nullable = true)\n",
      " |-- Horizontal_Distance_To_Roadways: integer (nullable = true)\n",
      " |-- Hillshade_9am: integer (nullable = true)\n",
      " |-- Hillshade_Noon: integer (nullable = true)\n",
      " |-- Hillshade_3pm: integer (nullable = true)\n",
      " |-- Horizontal_Distance_To_Fire_Points: integer (nullable = true)\n",
      " |-- Wilderness_Area_0: integer (nullable = true)\n",
      " |-- Wilderness_Area_1: integer (nullable = true)\n",
      " |-- Wilderness_Area_2: integer (nullable = true)\n",
      " |-- Wilderness_Area_3: integer (nullable = true)\n",
      " |-- Soil_Type_0: integer (nullable = true)\n",
      " |-- Soil_Type_1: integer (nullable = true)\n",
      " |-- Soil_Type_2: integer (nullable = true)\n",
      " |-- Soil_Type_3: integer (nullable = true)\n",
      " |-- Soil_Type_4: integer (nullable = true)\n",
      " |-- Soil_Type_5: integer (nullable = true)\n",
      " |-- Soil_Type_6: integer (nullable = true)\n",
      " |-- Soil_Type_7: integer (nullable = true)\n",
      " |-- Soil_Type_8: integer (nullable = true)\n",
      " |-- Soil_Type_9: integer (nullable = true)\n",
      " |-- Soil_Type_10: integer (nullable = true)\n",
      " |-- Soil_Type_11: integer (nullable = true)\n",
      " |-- Soil_Type_12: integer (nullable = true)\n",
      " |-- Soil_Type_13: integer (nullable = true)\n",
      " |-- Soil_Type_14: integer (nullable = true)\n",
      " |-- Soil_Type_15: integer (nullable = true)\n",
      " |-- Soil_Type_16: integer (nullable = true)\n",
      " |-- Soil_Type_17: integer (nullable = true)\n",
      " |-- Soil_Type_18: integer (nullable = true)\n",
      " |-- Soil_Type_19: integer (nullable = true)\n",
      " |-- Soil_Type_20: integer (nullable = true)\n",
      " |-- Soil_Type_21: integer (nullable = true)\n",
      " |-- Soil_Type_22: integer (nullable = true)\n",
      " |-- Soil_Type_23: integer (nullable = true)\n",
      " |-- Soil_Type_24: integer (nullable = true)\n",
      " |-- Soil_Type_25: integer (nullable = true)\n",
      " |-- Soil_Type_26: integer (nullable = true)\n",
      " |-- Soil_Type_27: integer (nullable = true)\n",
      " |-- Soil_Type_28: integer (nullable = true)\n",
      " |-- Soil_Type_29: integer (nullable = true)\n",
      " |-- Soil_Type_30: integer (nullable = true)\n",
      " |-- Soil_Type_31: integer (nullable = true)\n",
      " |-- Soil_Type_32: integer (nullable = true)\n",
      " |-- Soil_Type_33: integer (nullable = true)\n",
      " |-- Soil_Type_34: integer (nullable = true)\n",
      " |-- Soil_Type_35: integer (nullable = true)\n",
      " |-- Soil_Type_36: integer (nullable = true)\n",
      " |-- Soil_Type_37: integer (nullable = true)\n",
      " |-- Soil_Type_38: integer (nullable = true)\n",
      " |-- Soil_Type_39: integer (nullable = true)\n",
      " |-- Cover_Type: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Elevation=2596, Aspect=51, Slope=3, Horizontal_Distance_To_Hydrology=258, Vertical_Distance_To_Hydrology=0, Horizontal_Distance_To_Roadways=510, Hillshade_9am=221, Hillshade_Noon=232, Hillshade_3pm=148, Horizontal_Distance_To_Fire_Points=6279, Wilderness_Area_0=1, Wilderness_Area_1=0, Wilderness_Area_2=0, Wilderness_Area_3=0, Soil_Type_0=0, Soil_Type_1=0, Soil_Type_2=0, Soil_Type_3=0, Soil_Type_4=0, Soil_Type_5=0, Soil_Type_6=0, Soil_Type_7=0, Soil_Type_8=0, Soil_Type_9=0, Soil_Type_10=0, Soil_Type_11=0, Soil_Type_12=0, Soil_Type_13=0, Soil_Type_14=0, Soil_Type_15=0, Soil_Type_16=0, Soil_Type_17=0, Soil_Type_18=0, Soil_Type_19=0, Soil_Type_20=0, Soil_Type_21=0, Soil_Type_22=0, Soil_Type_23=0, Soil_Type_24=0, Soil_Type_25=0, Soil_Type_26=0, Soil_Type_27=0, Soil_Type_28=1, Soil_Type_29=0, Soil_Type_30=0, Soil_Type_31=0, Soil_Type_32=0, Soil_Type_33=0, Soil_Type_34=0, Soil_Type_35=0, Soil_Type_36=0, Soil_Type_37=0, Soil_Type_38=0, Soil_Type_39=0, Cover_Type=5.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainData, testData) = data.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputCols = trainData.drop('Cover_Type').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|featureVector                                                                                        |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1863.0,37.0,17.0,120.0,18.0,90.0,217.0,202.0,115.0,769.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1888.0,33.0,22.0,150.0,46.0,108.0,209.0,185.0,103.0,735.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1889.0,28.0,22.0,150.0,23.0,120.0,205.0,185.0,108.0,759.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1889.0,353.0,30.0,95.0,39.0,67.0,153.0,172.0,146.0,600.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1896.0,337.0,12.0,30.0,6.0,175.0,195.0,224.0,168.0,732.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1899.0,355.0,22.0,153.0,43.0,124.0,178.0,195.0,151.0,819.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1901.0,311.0,9.0,30.0,2.0,190.0,195.0,234.0,179.0,726.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,16],[1903.0,67.0,16.0,108.0,36.0,120.0,234.0,207.0,100.0,969.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1904.0,51.0,26.0,67.0,30.0,162.0,222.0,175.0,72.0,711.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1905.0,33.0,27.0,90.0,46.0,150.0,204.0,171.0,89.0,725.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1906.0,356.0,20.0,150.0,55.0,120.0,184.0,201.0,151.0,726.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1916.0,24.0,25.0,212.0,74.0,175.0,197.0,177.0,105.0,789.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1919.0,30.0,22.0,67.0,9.0,256.0,208.0,188.0,107.0,661.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1927.0,54.0,25.0,190.0,76.0,175.0,225.0,177.0,71.0,735.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1927.0,333.0,27.0,218.0,72.0,190.0,149.0,195.0,180.0,859.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1928.0,252.0,31.0,30.0,14.0,180.0,138.0,243.0,233.0,765.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,16],[1929.0,172.0,16.0,90.0,30.0,108.0,229.0,246.0,143.0,787.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1932.0,251.0,26.0,30.0,10.0,240.0,154.0,247.0,224.0,743.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,5,6,7,8,9,13,23],[1944.0,33.0,22.0,30.0,210.0,187.0,104.0,277.0,1.0,1.0])                 |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1944.0,339.0,30.0,240.0,93.0,210.0,142.0,181.0,169.0,815.0,1.0,1.0])|\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=inputCols,\n",
    "    outputCol=\"featureVector\")\n",
    "assembledTrainData = assembler.transform(trainData)\n",
    "assembledTrainData.select('featureVector').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_45fd98cbd365066ceb77) of depth 5 with 63 nodes\n",
      "  If (feature 0 <= 3036.5)\n",
      "   If (feature 0 <= 2555.5)\n",
      "    If (feature 10 <= 0.5)\n",
      "     If (feature 0 <= 2448.5)\n",
      "      If (feature 3 <= 15.0)\n",
      "       Predict: 4.0\n",
      "      Else (feature 3 > 15.0)\n",
      "       Predict: 3.0\n",
      "     Else (feature 0 > 2448.5)\n",
      "      If (feature 17 <= 0.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 17 > 0.5)\n",
      "       Predict: 3.0\n",
      "    Else (feature 10 > 0.5)\n",
      "     If (feature 22 <= 0.5)\n",
      "      If (feature 9 <= 4604.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 9 > 4604.5)\n",
      "       Predict: 2.0\n",
      "     Else (feature 22 > 0.5)\n",
      "      If (feature 9 <= 1093.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 9 > 1093.5)\n",
      "       Predict: 2.0\n",
      "   Else (feature 0 > 2555.5)\n",
      "    If (feature 15 <= 0.5)\n",
      "     If (feature 0 <= 2939.5)\n",
      "      If (feature 17 <= 0.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 17 > 0.5)\n",
      "       Predict: 3.0\n",
      "     Else (feature 0 > 2939.5)\n",
      "      If (feature 3 <= 142.0)\n",
      "       Predict: 2.0\n",
      "      Else (feature 3 > 142.0)\n",
      "       Predict: 2.0\n",
      "    Else (feature 15 > 0.5)\n",
      "     If (feature 9 <= 1360.5)\n",
      "      If (feature 7 <= 215.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 7 > 215.5)\n",
      "       Predict: 3.0\n",
      "     Else (feature 9 > 1360.5)\n",
      "      If (feature 3 <= 241.0)\n",
      "       Predict: 2.0\n",
      "      Else (feature 3 > 241.0)\n",
      "       Predict: 3.0\n",
      "  Else (feature 0 > 3036.5)\n",
      "   If (feature 0 <= 3318.5)\n",
      "    If (feature 7 <= 239.5)\n",
      "     If (feature 0 <= 3121.5)\n",
      "      If (feature 3 <= 191.0)\n",
      "       Predict: 1.0\n",
      "      Else (feature 3 > 191.0)\n",
      "       Predict: 1.0\n",
      "     Else (feature 0 > 3121.5)\n",
      "      If (feature 5 <= 1097.0)\n",
      "       Predict: 1.0\n",
      "      Else (feature 5 > 1097.0)\n",
      "       Predict: 1.0\n",
      "    Else (feature 7 > 239.5)\n",
      "     If (feature 3 <= 330.5)\n",
      "      If (feature 0 <= 3186.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 0 > 3186.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 3 > 330.5)\n",
      "      If (feature 0 <= 3206.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 0 > 3206.5)\n",
      "       Predict: 1.0\n",
      "   Else (feature 0 > 3318.5)\n",
      "    If (feature 12 <= 0.5)\n",
      "     If (feature 3 <= 307.5)\n",
      "      If (feature 6 <= 207.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 6 > 207.5)\n",
      "       Predict: 7.0\n",
      "     Else (feature 3 > 307.5)\n",
      "      If (feature 11 <= 0.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 11 > 0.5)\n",
      "       Predict: 1.0\n",
      "    Else (feature 12 > 0.5)\n",
      "     If (feature 45 <= 0.5)\n",
      "      If (feature 0 <= 3377.5)\n",
      "       Predict: 7.0\n",
      "      Else (feature 0 > 3377.5)\n",
      "       Predict: 7.0\n",
      "     Else (feature 45 > 0.5)\n",
      "      If (feature 5 <= 998.0)\n",
      "       Predict: 7.0\n",
      "      Else (feature 5 > 998.0)\n",
      "       Predict: 1.0\n",
      "\n",
      "(54,[0,3,5,6,7,9,10,11,12,15,17,22,45],[0.791877082352102,0.05108812132218045,0.012560669345548918,0.0025879965046360326,0.026399659218954718,0.0022039634744590226,0.027157209685963746,0.002923975546254399,0.011064503894730184,0.024510179615058268,0.030734267106604343,0.0003099185997944373,0.016582453333713523])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(labelCol=\"Cover_Type\", featuresCol=\"featureVector\", predictionCol=\"prediction\")\n",
    "model = classifier.fit(assembledTrainData)\n",
    "\n",
    "print(model.toDebugString)\n",
    "print(model.featureImportances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------------------------------------------------------------------------------------------------+\n",
      "|Cover_Type|prediction|probability                                                                                      |\n",
      "+----------+----------+-------------------------------------------------------------------------------------------------+\n",
      "|6.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|3.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|3.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "|3.0       |4.0       |[0.0,0.0,0.041504539559014265,0.28728923476005186,0.4377431906614786,0.0,0.23346303501945526,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.0326005308227753,0.6326305773949622,0.05082878461615504,0.0,0.28394010716610746,0.0]  |\n",
      "+----------+----------+-------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(assembledTrainData)\n",
    "predictions.select([\"Cover_Type\", \"prediction\", \"probability\"]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Cover_Type\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6964547887828391"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.setMetricName(\"accuracy\").evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6795884301953133"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.setMetricName(\"f1\").evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix - not supported in PySpark ML library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "inputCols = trainData.columns[:-1]\n",
    "assembler = VectorAssembler(inputCols=inputCols, outputCol=\"featureVector\")\n",
    "classifier = DecisionTreeClassifier(labelCol=\"Cover_Type\", featuresCol=\"featureVector\", predictionCol=\"prediction\")\n",
    "pipeline = Pipeline(stages=[assembler, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(classifier.impurity, [\"gini\", \"entropy\"])\\\n",
    "    .addGrid(classifier.maxDepth, [10, 30])\\\n",
    "    .addGrid(classifier.maxBins, [40, 100])\\\n",
    "    .addGrid(classifier.minInfoGain, [0.0, 0.05])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6964547887828391"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclassEval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Cover_Type\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\")\n",
    "multiclassEval.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "\n",
    "validator = TrainValidationSplit(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=multiclassEval,\n",
    "    trainRatio=0.9)\n",
    "validatorModel = validator.fit(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = validatorModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='DecisionTreeClassifier_432b9017f8fe9ad11f9a', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees.'): False,\n",
       " Param(parent='DecisionTreeClassifier_432b9017f8fe9ad11f9a', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext'): 10,\n",
       " Param(parent='DecisionTreeClassifier_432b9017f8fe9ad11f9a', name='featuresCol', doc='features column name'): 'featureVector',\n",
       " Param(parent='DecisionTreeClassifier_432b9017f8fe9ad11f9a', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       " Param(parent='DecisionTreeClassifier_432b9017f8fe9ad11f9a', name='labelCol', doc='label column name'): 'Cover_Type',\n",
       " Param(parent='DecisionTreeClassifier_432b9017f8fe9ad11f9a', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 100,\n",
       " Param(parent='DecisionTreeClassifier_432b9017f8fe9ad11f9a', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 30,\n",
       " Param(parent='DecisionTreeClassifier_432b9017f8fe9ad11f9a', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation.'): 256,\n",
       " Param(parent='DecisionTreeClassifier_432b9017f8fe9ad11f9a', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0,\n",
       " Param(parent='DecisionTreeClassifier_432b9017f8fe9ad11f9a', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split.  If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1,\n",
       " Param(parent='DecisionTreeClassifier_432b9017f8fe9ad11f9a', name='predictionCol', doc='prediction column name'): 'prediction',\n",
       " Param(parent='DecisionTreeClassifier_432b9017f8fe9ad11f9a', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities'): 'probability',\n",
       " Param(parent='DecisionTreeClassifier_432b9017f8fe9ad11f9a', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name'): 'rawPrediction',\n",
       " Param(parent='DecisionTreeClassifier_432b9017f8fe9ad11f9a', name='seed', doc='random seed'): 7099840646758736014}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.stages[-1].extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.775266360157476,\n",
       " 0.6723012966990612,\n",
       " 0.7809101671117474,\n",
       " 0.6711450045425763,\n",
       " 0.9215097871871817,\n",
       " 0.6723012966990612,\n",
       " 0.92654791729758,\n",
       " 0.6711450045425763,\n",
       " 0.7726234066569392,\n",
       " 0.7143958373482366,\n",
       " 0.7717424221567601,\n",
       " 0.713900283566886,\n",
       " 0.9262175481100129,\n",
       " 0.7231781515843956,\n",
       " 0.9294661784544228,\n",
       " 0.727197643366462]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramsAndMetrics = validatorModel.validationMetrics\n",
    "paramsAndMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9303621169916435"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclassEval.evaluate(bestModel.transform(testData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### undoing the one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildernessCols = []\n",
    "for i in range(4):\n",
    "    wildernessCols += [\"Wilderness_Area_\"+str(i),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildernessAssembler = VectorAssembler(\n",
    "    inputCols=wildernessCols,\n",
    "    outputCol=\"wilderness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, DoubleType, StructType\n",
    "\n",
    "unhotudf = udf(lambda x: float(x.toArray().nonzero()[0]), DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Elevation=2596, Aspect=51, Slope=3, Horizontal_Distance_To_Hydrology=258, Vertical_Distance_To_Hydrology=0, Horizontal_Distance_To_Roadways=510, Hillshade_9am=221, Hillshade_Noon=232, Hillshade_3pm=148, Horizontal_Distance_To_Fire_Points=6279, Soil_Type_0=0, Soil_Type_1=0, Soil_Type_2=0, Soil_Type_3=0, Soil_Type_4=0, Soil_Type_5=0, Soil_Type_6=0, Soil_Type_7=0, Soil_Type_8=0, Soil_Type_9=0, Soil_Type_10=0, Soil_Type_11=0, Soil_Type_12=0, Soil_Type_13=0, Soil_Type_14=0, Soil_Type_15=0, Soil_Type_16=0, Soil_Type_17=0, Soil_Type_18=0, Soil_Type_19=0, Soil_Type_20=0, Soil_Type_21=0, Soil_Type_22=0, Soil_Type_23=0, Soil_Type_24=0, Soil_Type_25=0, Soil_Type_26=0, Soil_Type_27=0, Soil_Type_28=1, Soil_Type_29=0, Soil_Type_30=0, Soil_Type_31=0, Soil_Type_32=0, Soil_Type_33=0, Soil_Type_34=0, Soil_Type_35=0, Soil_Type_36=0, Soil_Type_37=0, Soil_Type_38=0, Soil_Type_39=0, Cover_Type=5.0, wilderness=0.0)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withWilderness = wildernessAssembler.transform(data)\n",
    "withWilderness = withWilderness\\\n",
    "    .drop(*wildernessCols)\\\n",
    "    .withColumn(\"wilderness\", unhotudf(withWilderness['wilderness']))\n",
    "withWilderness.take(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soilCols = []\n",
    "for i in range(40):\n",
    "    soilCols += [\"Soil_Type_\"+str(i),]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Elevation=2596, Aspect=51, Slope=3, Horizontal_Distance_To_Hydrology=258, Vertical_Distance_To_Hydrology=0, Horizontal_Distance_To_Roadways=510, Hillshade_9am=221, Hillshade_Noon=232, Hillshade_3pm=148, Horizontal_Distance_To_Fire_Points=6279, Cover_Type=5.0, wilderness=0.0, soil=28.0)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soilAssembler = VectorAssembler(\n",
    "        inputCols=soilCols,\n",
    "        outputCol=\"soil\")\n",
    "\n",
    "withWilderness = soilAssembler.transform(withWilderness)\n",
    "unencData = withWilderness\\\n",
    "    .drop(*soilCols)\\\n",
    "    .withColumn(\"soil\", unhotudf(withWilderness['soil']))\n",
    "unencData.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier with unencoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unencTrainData, unencTestData) = unencData.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorIndexer\n",
    "\n",
    "inputCols = unencTrainData.drop('Cover_Type').columns\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=inputCols,\n",
    "    outputCol=\"featureVector\")\n",
    "indexer = VectorIndexer(\n",
    "    maxCategories=40,\n",
    "    inputCol=\"featureVector\",\n",
    "    outputCol=\"indexedVector\")\n",
    "classifier = DecisionTreeClassifier(\n",
    "    seed=42,\n",
    "    labelCol=\"Cover_Type\",\n",
    "    featuresCol=\"indexedVector\",\n",
    "    predictionCol=\"prediction\")\n",
    "pipeline = Pipeline(stages=[assembler, indexer, classifier])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(\n",
    "    seed=42,\n",
    "    maxBins=40,\n",
    "    labelCol=\"Cover_Type\",\n",
    "    featuresCol=\"indexedVector\",\n",
    "    predictionCol=\"prediction\")\n",
    "pipeline = Pipeline(stages=[assembler, indexer, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(classifier.minInfoGain, [0.01, 0.1])\\\n",
    "    .addGrid(classifier.numTrees, [1, 20])\\\n",
    "    .addGrid(classifier.featureSubsetStrategy, [10,20])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclassEval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Cover_Type\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = TrainValidationSplit(\n",
    "    seed=42,\n",
    "    estimator=pipeline,\n",
    "    evaluator=multiclassEval,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    trainRatio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Param(parent='RandomForestClassifier_45e9a5ace69b97fb1ebc', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees.'): False, Param(parent='RandomForestClassifier_45e9a5ace69b97fb1ebc', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext'): 10, Param(parent='RandomForestClassifier_45e9a5ace69b97fb1ebc', name='featureSubsetStrategy', doc='The number of features to consider for splits at each tree node. Supported options: auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n].'): 'auto', Param(parent='RandomForestClassifier_45e9a5ace69b97fb1ebc', name='featuresCol', doc='features column name'): 'indexedVector', Param(parent='RandomForestClassifier_45e9a5ace69b97fb1ebc', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini', Param(parent='RandomForestClassifier_45e9a5ace69b97fb1ebc', name='labelCol', doc='label column name'): 'Cover_Type', Param(parent='RandomForestClassifier_45e9a5ace69b97fb1ebc', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40, Param(parent='RandomForestClassifier_45e9a5ace69b97fb1ebc', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='RandomForestClassifier_45e9a5ace69b97fb1ebc', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation.'): 256, Param(parent='RandomForestClassifier_45e9a5ace69b97fb1ebc', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.01, Param(parent='RandomForestClassifier_45e9a5ace69b97fb1ebc', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split.  If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='RandomForestClassifier_45e9a5ace69b97fb1ebc', name='numTrees', doc='Number of trees to train (>= 1)'): 1, Param(parent='RandomForestClassifier_45e9a5ace69b97fb1ebc', name='predictionCol', doc='prediction column name'): 'prediction', Param(parent='RandomForestClassifier_45e9a5ace69b97fb1ebc', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities'): 'probability', Param(parent='RandomForestClassifier_45e9a5ace69b97fb1ebc', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name'): 'rawPrediction', Param(parent='RandomForestClassifier_45e9a5ace69b97fb1ebc', name='seed', doc='random seed'): 42, Param(parent='RandomForestClassifier_45e9a5ace69b97fb1ebc', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}\n",
      "Wall time: 12min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "validatorModel = validator.fit(unencTrainData)\n",
    "bestModel = validatorModel.bestModel\n",
    "forestModel = bestModel.stages[-1]\n",
    "print(forestModel.extractParamMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forestModel.getNumTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Elevation', 0.7923040942711657),\n",
       " ('soil', 0.11768096858410305),\n",
       " ('wilderness', 0.03845661669381131),\n",
       " ('Horizontal_Distance_To_Roadways', 0.02843022997776665),\n",
       " ('Horizontal_Distance_To_Fire_Points', 0.012640611525555063),\n",
       " ('Horizontal_Distance_To_Hydrology', 0.005253740128991872),\n",
       " ('Vertical_Distance_To_Hydrology', 0.0033425724201158395),\n",
       " ('Aspect', 0.001891166398490582),\n",
       " ('Slope', 0.0),\n",
       " ('Hillshade_9am', 0.0),\n",
       " ('Hillshade_Noon', 0.0),\n",
       " ('Hillshade_3pm', 0.0)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(inputCols, forestModel.featureImportances)), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.697731196054254"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testAccuracy = multiclassEval.evaluate(bestModel.transform(unencTestData))\n",
    "testAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-----+--------------------------------+------------------------------+-------------------------------+-------------+--------------+-------------+----------------------------------+----------+----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|Elevation|Aspect|Slope|Horizontal_Distance_To_Hydrology|Vertical_Distance_To_Hydrology|Horizontal_Distance_To_Roadways|Hillshade_9am|Hillshade_Noon|Hillshade_3pm|Horizontal_Distance_To_Fire_Points|wilderness|soil|       featureVector|       indexedVector|       rawPrediction|         probability|prediction|\n",
      "+---------+------+-----+--------------------------------+------------------------------+-------------------------------+-------------+--------------+-------------+----------------------------------+----------+----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|     1896|   337|   12|                              30|                             6|                            175|          195|           224|          168|                               732|       3.0| 4.0|[1896.0,337.0,12....|[1896.0,337.0,12....|[0.0,7.6379606645...|[0.0,7.6379606645...|       3.0|\n",
      "|     1927|    54|   25|                             190|                            76|                            175|          225|           177|           71|                               735|       3.0| 0.0|[1927.0,54.0,25.0...|[1927.0,54.0,25.0...|[0.0,7.6379606645...|[0.0,7.6379606645...|       3.0|\n",
      "|     1936|   163|   13|                             120|                            37|                            127|          232|           243|          140|                               816|       3.0| 2.0|[1936.0,163.0,13....|[1936.0,163.0,13....|[0.0,0.0,0.017418...|[0.0,0.0,0.017418...|       3.0|\n",
      "|     1944|   339|   30|                             240|                            93|                            210|          142|           181|          169|                               815|       3.0| 4.0|[1944.0,339.0,30....|[1944.0,339.0,30....|[0.0,7.6379606645...|[0.0,7.6379606645...|       3.0|\n",
      "|     1948|   347|   13|                               0|                             0|                            180|          194|           218|          162|                               558|       3.0| 9.0|[1948.0,347.0,13....|[1948.0,347.0,13....|[0.0,0.0,0.047072...|[0.0,0.0,0.047072...|       4.0|\n",
      "|     1954|    47|   32|                             218|                            99|                            210|          213|           155|           55|                               927|       3.0| 0.0|[1954.0,47.0,32.0...|[1954.0,47.0,32.0...|[0.0,7.6379606645...|[0.0,7.6379606645...|       3.0|\n",
      "|     1992|   358|   33|                             228|                           143|                            212|          151|           160|          132|                               750|       3.0| 4.0|[1992.0,358.0,33....|[1992.0,358.0,33....|[0.0,7.6379606645...|[0.0,7.6379606645...|       3.0|\n",
      "|     1993|   291|   41|                             127|                            96|                            150|           78|           197|          240|                               300|       3.0| 9.0|[1993.0,291.0,41....|[1993.0,291.0,41....|[0.0,0.0,0.036887...|[0.0,0.0,0.036887...|       3.0|\n",
      "|     2005|   122|   30|                             277|                           102|                            277|          254|           200|           50|                               810|       3.0| 2.0|[2005.0,122.0,30....|[2005.0,122.0,30....|[0.0,0.0,0.017418...|[0.0,0.0,0.017418...|       3.0|\n",
      "|     2005|   159|   28|                              30|                             1|                            210|          236|           232|          107|                               247|       3.0| 5.0|[2005.0,159.0,28....|[2005.0,159.0,28....|[0.0,7.6379606645...|[0.0,7.6379606645...|       3.0|\n",
      "|     2005|   284|   29|                              30|                            20|                            150|          130|           227|          230|                               551|       3.0| 3.0|[2005.0,284.0,29....|[2005.0,284.0,29....|[0.0,7.6379606645...|[0.0,7.6379606645...|       3.0|\n",
      "|     2006|    79|   16|                               0|                             0|                            192|          240|           209|           95|                               339|       3.0|16.0|[2006.0,79.0,16.0...|[2006.0,79.0,16.0...|[0.0,0.0,0.047072...|[0.0,0.0,0.047072...|       4.0|\n",
      "|     2008|   226|   32|                              30|                            12|                            108|          161|           250|          210|                               295|       3.0| 4.0|[2008.0,226.0,32....|[2008.0,226.0,32....|[0.0,7.6379606645...|[0.0,7.6379606645...|       3.0|\n",
      "|     2018|   341|   27|                             351|                            34|                            390|          152|           188|          168|                               190|       3.0| 4.0|[2018.0,341.0,27....|[2018.0,341.0,27....|[0.0,7.6379606645...|[0.0,7.6379606645...|       3.0|\n",
      "|     2021|   343|   13|                               0|                             0|                            360|          192|           219|          165|                               458|       3.0|13.0|[2021.0,343.0,13....|[2021.0,343.0,13....|[0.0,0.0,0.047072...|[0.0,0.0,0.047072...|       4.0|\n",
      "|     2025|    33|   19|                              42|                             9|                            424|          213|           195|          111|                               503|       3.0| 9.0|[2025.0,33.0,19.0...|[2025.0,33.0,19.0...|[0.0,0.0,0.036887...|[0.0,0.0,0.036887...|       3.0|\n",
      "|     2027|    42|   13|                               0|                             0|                            553|          222|           212|          123|                               497|       3.0|16.0|[2027.0,42.0,13.0...|[2027.0,42.0,13.0...|[0.0,0.0,0.047072...|[0.0,0.0,0.047072...|       4.0|\n",
      "|     2033|    39|   20|                              42|                            10|                            514|          217|           192|          103|                               564|       3.0| 9.0|[2033.0,39.0,20.0...|[2033.0,39.0,20.0...|[0.0,0.0,0.036887...|[0.0,0.0,0.036887...|       3.0|\n",
      "|     2036|    49|    9|                               0|                             0|                            450|          224|           220|          129|                               644|       3.0|16.0|[2036.0,49.0,9.0,...|[2036.0,49.0,9.0,...|[0.0,0.0,0.047072...|[0.0,0.0,0.047072...|       4.0|\n",
      "|     2037|    57|   32|                              30|                            17|                            228|          223|           155|           41|                               484|       3.0| 9.0|[2037.0,57.0,32.0...|[2037.0,57.0,32.0...|[0.0,0.0,0.036887...|[0.0,0.0,0.036887...|       3.0|\n",
      "+---------+------+-----+--------------------------------+------------------------------+-------------------------------+-------------+--------------+-------------+----------------------------------+----------+----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestModel.transform(unencTestData.drop(\"Cover_Type\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|featureVector                                                                                        |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1863.0,37.0,17.0,120.0,18.0,90.0,217.0,202.0,115.0,769.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1888.0,33.0,22.0,150.0,46.0,108.0,209.0,185.0,103.0,735.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1889.0,28.0,22.0,150.0,23.0,120.0,205.0,185.0,108.0,759.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1889.0,353.0,30.0,95.0,39.0,67.0,153.0,172.0,146.0,600.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1896.0,337.0,12.0,30.0,6.0,175.0,195.0,224.0,168.0,732.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1899.0,355.0,22.0,153.0,43.0,124.0,178.0,195.0,151.0,819.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1901.0,311.0,9.0,30.0,2.0,190.0,195.0,234.0,179.0,726.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,16],[1903.0,67.0,16.0,108.0,36.0,120.0,234.0,207.0,100.0,969.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1904.0,51.0,26.0,67.0,30.0,162.0,222.0,175.0,72.0,711.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1905.0,33.0,27.0,90.0,46.0,150.0,204.0,171.0,89.0,725.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,16],[1905.0,77.0,21.0,90.0,38.0,120.0,241.0,196.0,75.0,1025.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1906.0,356.0,20.0,150.0,55.0,120.0,184.0,201.0,151.0,726.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1908.0,323.0,32.0,150.0,52.0,120.0,125.0,190.0,196.0,765.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1916.0,24.0,25.0,212.0,74.0,175.0,197.0,177.0,105.0,789.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1919.0,30.0,22.0,67.0,9.0,256.0,208.0,188.0,107.0,661.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1925.0,352.0,22.0,210.0,74.0,182.0,176.0,197.0,155.0,779.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1927.0,54.0,25.0,190.0,76.0,175.0,225.0,177.0,71.0,735.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1927.0,333.0,27.0,218.0,72.0,190.0,149.0,195.0,180.0,859.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1928.0,252.0,31.0,30.0,14.0,180.0,138.0,243.0,233.0,765.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,16],[1929.0,172.0,16.0,90.0,30.0,108.0,229.0,246.0,143.0,787.0,1.0,1.0]) |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Cover_Type|prediction|probability                                                                                                                                                               |\n",
      "+----------+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|6.0       |3.0       |[1.6182482693329704E-8,1.94965811173266E-8,0.00159246095283688,0.8924487415525697,0.049758270261793955,2.941291766413457E-4,0.05590634718665842,1.519043594595538E-8]     |\n",
      "|6.0       |3.0       |[1.890870828910457E-8,3.257606067824836E-8,0.0016365693494962668,0.9023897384300623,0.039221926863541486,2.8877761264974977E-4,0.056462903506807646,3.2752673522665704E-8]|\n",
      "|6.0       |3.0       |[2.480712029673007E-8,5.544760267386476E-7,5.268762938274234E-5,0.6991579416538459,0.06096178825874422,7.452216270670593E-5,0.23975217919609462,3.018160788088358E-7]     |\n",
      "|6.0       |3.0       |[1.6520538942410883E-8,5.366512826737164E-7,2.6304912788313532E-5,0.6599360969430871,0.007679358106856894,6.509856475887428E-5,0.3322923414399681,2.4686071916052565E-7]  |\n",
      "|6.0       |3.0       |[1.5579348805820677E-8,1.7836634334207777E-7,3.0491684820488914E-5,0.6050236678076296,0.023554310280350252,1.2449691303527516E-4,0.3712667642533518,7.511512037040736E-8] |\n",
      "|6.0       |3.0       |[1.4917517251210987E-8,2.4746628010597683E-7,2.9498362295391852E-5,0.6918788451224595,0.010973633944540845,9.21820472887281E-5,0.2970254510649396,1.2707467860441252E-7]  |\n",
      "|6.0       |3.0       |[1.9370615836238864E-8,2.544171236299813E-7,3.9447426061805225E-5,0.6230529567972733,0.05919580825385491,1.244922038705301E-4,0.3175869363154408,8.521575897976282E-8]    |\n",
      "|3.0       |3.0       |[2.278830337618816E-8,6.904998553392322E-8,0.012425801321372108,0.5457671425415658,0.4176816041687424,1.7066905997086214E-5,0.024108245627690972,4.759634273963775E-8]    |\n",
      "|6.0       |3.0       |[2.165192854882965E-8,3.589578975823019E-7,2.4348713204920145E-5,0.7101289874205872,0.08153978065045916,8.426073421857644E-5,0.20822195117566425,2.9069603984198527E-7]   |\n",
      "|6.0       |3.0       |[2.6262207558487075E-8,6.565848918579924E-7,3.716057618475334E-5,0.683856344303867,0.06219998363401253,7.885387560425853E-5,0.2538264990067945,4.7575643743691745E-7]     |\n",
      "|3.0       |3.0       |[1.9143712584419805E-8,5.0801476734185566E-8,0.007645333254562574,0.569980145275263,0.4023583768396781,1.5527971080674225E-5,0.02000050614637067,4.056785575985844E-8]    |\n",
      "|6.0       |3.0       |[1.3457929180333555E-8,1.855950584353224E-8,0.0010452374512993484,0.9250633176406827,0.017314199450083577,3.448114778885026E-4,0.056232386237235775,1.5725374924431026E-8]|\n",
      "|6.0       |3.0       |[1.3103995202170394E-8,6.676407200992359E-7,4.268508862808984E-5,0.6498773684643704,0.0031503836706087843,4.397010620965357E-5,0.3468848260401974,8.588527030487425E-8]   |\n",
      "|6.0       |3.0       |[2.251284047063103E-8,6.262812502627948E-8,0.0021120360282991715,0.9116605563366666,0.02831109108883995,2.8130716122384114E-4,0.05763486301611961,6.122788515927196E-8]   |\n",
      "|6.0       |3.0       |[2.7427099590305384E-8,6.96572270876606E-7,4.971638439634E-5,0.6468846716520913,0.07642123481245787,7.96295180447801E-5,0.27656366231077384,3.613228654182818E-7]         |\n",
      "|6.0       |3.0       |[1.5192616474054568E-8,2.8209056715492005E-7,3.2168988172059954E-5,0.7149780632524354,0.008986528649633774,1.0045860333833225E-4,0.2759023470673048,1.3615593217264724E-7]|\n",
      "|6.0       |3.0       |[2.093349141798528E-8,3.360378791178673E-7,2.581968324185175E-5,0.7713495802995562,0.0632255382220176,9.860101344257073E-5,0.1652998064972342,2.973131366778624E-7]       |\n",
      "|6.0       |3.0       |[1.4389611165127601E-8,4.6714153581889864E-7,4.355978994269799E-5,0.6887614818708742,0.00470859500664134,6.652523951007322E-5,0.30641924567416423,1.1088772044691945E-7]  |\n",
      "|6.0       |3.0       |[5.80623363374281E-9,1.580467714384286E-7,2.5183086340690144E-5,0.7756651416283369,0.0058506947951909175,2.96288740081292E-5,0.21842918544446574,2.318652519206939E-9]    |\n",
      "|3.0       |3.0       |[1.0397436955199482E-8,1.888260316973408E-8,0.0068907475042623255,0.7543393069148905,0.2199459327200887,1.5847369411701247E-5,0.018808133657237873,2.5540688306106417E-9] |\n",
      "+----------+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(trainData, testData) = data.randomSplit([0.9, 0.1])\n",
    "\n",
    "inputCols = trainData.drop('Cover_Type').columns\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=inputCols,\n",
    "    outputCol=\"featureVector\")\n",
    "assembledTrainData = assembler.transform(trainData)\n",
    "assembledTrainData.select('featureVector').show(truncate=False)\n",
    "\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "classifier = LogisticRegression(labelCol=\"Cover_Type\", featuresCol=\"featureVector\", predictionCol=\"prediction\")\n",
    "model = classifier.fit(assembledTrainData)\n",
    "\n",
    "#print(model.toDebugString)\n",
    "#print(model.featureImportances)\n",
    "\n",
    "predictions = model.transform(assembledTrainData)\n",
    "predictions.select([\"Cover_Type\", \"prediction\", \"probability\"]).show(truncate=False)\n",
    "\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Cover_Type\", predictionCol=\"prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluator.setMetricName(\"accuracy\").evaluate(predictions)\n",
    "evaluator.setMetricName(\"f1\").evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - ParamGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(classifier.regParam, [0.1, 0.2])\\\n",
    "    .addGrid(classifier.elasticNetParam, [0.001, 0.01])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclassEval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Cover_Type\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = TrainValidationSplit(\n",
    "    estimator=pipeline,\n",
    "    evaluator=multiclassEval,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    trainRatio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "validatorModel = validator.fit(unencTrainData)\n",
    "bestModel = validatorModel.bestModel\n",
    "forestModel = bestModel.stages[-1]\n",
    "print(forestModel.extractParamMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAccuracy = multiclassEval.evaluate(bestModel.transform(unencTestData))\n",
    "testAccuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
